<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2 | Scientific Data</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/sdata.rss"/>


    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"data descriptor","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"atmospheric-dynamics;geodynamics","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Scientific Data","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Data Descriptor"}},"article":{"doi":"10.1038/s41597-022-01878-2"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":true,"legacy":{"webtrendsLicenceType":"http://creativecommons.org/licenses/by/4.0/"}}},"contentInfo":{"authors":["Cesar Aybar","Luis Ysuhuaylas","Jhomira Loja","Karen Gonzales","Fernando Herrera","Lesly Bautista","Roy Yali","Angie Flores","Lissette Diaz","Nicole Cuenca","Wendy Espinoza","Fernando Prudencio","Valeria Llactayo","David Montero","Martin Sudmanns","Dirk Tiede","Gonzalo Mateo-García","Luis Gómez-Chova"],"publishedAt":1671840000,"publishedAtString":"2022-12-24","title":"CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"sdata","title":"scientific data","volume":"9","issue":"1"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"PL","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-card--major .c-card__title,.u-h1,.u-h2,h1,h2{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h3,h4,h5,h6{letter-spacing:-.0117156rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}.c-card--major .c-card__title,.u-h1,.u-h2,button,h1,h2{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}button{border-radius:0;cursor:pointer}.c-card--major .c-card__title,.u-h1,.u-h2,h1,h2{font-weight:700}h1{font-size:2rem;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,h2{font-size:1.5rem;letter-spacing:-.0117156rem;line-height:1.6rem}.u-h3{letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h3,h4,h5,h6{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-reading-companion__figure-title,.u-h4,h3,h4,h5,h6{letter-spacing:-.0117156rem}.c-reading-companion__figure-title,.u-h4,h4{font-size:1.125rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-link-inherit{color:inherit}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-text-bold{font-weight:700}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-6f3d870973.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-6f3d870973.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-6172a28acf.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-e6f6eaf885.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-0657cbacd9.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-b55cca8aa9.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2","description":"Accurately characterizing clouds and their shadows is a long-standing problem in the Earth Observation community. Recent works showcase the necessity to improve cloud detection methods for imagery acquired by the Sentinel-2 satellites. However, the lack of consensus and transparency in existing reference datasets hampers the benchmarking of current cloud detection methods. Exploiting the analysis-ready data offered by the Copernicus program, we created CloudSEN12, a new multi-temporal global dataset to foster research in cloud and cloud shadow detection. CloudSEN12 has 49,400 image patches, including (1) Sentinel-2 level-1C and level-2A multi-spectral data, (2) Sentinel-1 synthetic aperture radar data, (3) auxiliary remote sensing products, (4) different hand-crafted annotations to label the presence of thick and thin clouds and cloud shadows, and (5) the results from eight state-of-the-art cloud detection algorithms. At present, CloudSEN12 exceeds all previous efforts in terms of annotation richness, scene variability, geographic distribution, metadata complexity, quality control, and number of samples. \n                \n                  \n                  \n                  \n                \n              ","datePublished":"2022-12-24T00:00:00Z","dateModified":"2022-12-24T00:00:00Z","pageStart":"1","pageEnd":"17","license":"http://creativecommons.org/licenses/by/4.0/","sameAs":"https://doi.org/10.1038/s41597-022-01878-2","keywords":["Atmospheric dynamics","Geodynamics","Science","Humanities and Social Sciences","multidisciplinary"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig1_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig2_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig4_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig5_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig6_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig7_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig8_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig9_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig10_HTML.png"],"isPartOf":{"name":"Scientific Data","issn":["2052-4463"],"volumeNumber":"9","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group UK","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Cesar Aybar","url":"http://orcid.org/0000-0003-2745-9535","affiliation":[{"name":"University of Valencia","address":{"name":"Image Processing Laboratory, University of Valencia, Valencia, Spain","@type":"PostalAddress"},"@type":"Organization"},{"name":"University of Salzburg","address":{"name":"Department of Geoinformatics – Z_GIS, University of Salzburg, Salzburg, Austria","@type":"PostalAddress"},"@type":"Organization"},{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"email":"csaybar@gmail.com","@type":"Person"},{"name":"Luis Ysuhuaylas","url":"http://orcid.org/0000-0001-9819-703X","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Jhomira Loja","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Karen Gonzales","url":"http://orcid.org/0000-0001-7634-684X","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Fernando Herrera","url":"http://orcid.org/0000-0002-8545-0806","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Lesly Bautista","url":"http://orcid.org/0000-0003-3523-8687","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Roy Yali","affiliation":[{"name":"Pontifical Catholic University of Peru","address":{"name":"Research Group on Artificial Intelligence, Pontifical Catholic University of Peru, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Angie Flores","url":"http://orcid.org/0000-0002-5294-9635","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Lissette Diaz","url":"http://orcid.org/0000-0003-3789-0927","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Nicole Cuenca","url":"http://orcid.org/0000-0002-9046-7987","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Wendy Espinoza","url":"http://orcid.org/0000-0002-6061-814X","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Fernando Prudencio","url":"http://orcid.org/0000-0003-1169-3618","affiliation":[{"name":"Geophysical Institute of Peru","address":{"name":"Sub-directorate of Atmospheric and Hydrospheric Sciences, Geophysical Institute of Peru, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Valeria Llactayo","url":"http://orcid.org/0000-0002-3267-7775","affiliation":[{"name":"National University of San Marcos","address":{"name":"High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"David Montero","url":"http://orcid.org/0000-0002-9010-3286","affiliation":[{"name":"Leipzig University","address":{"name":"Remote Sensing Centre for Earth Systems Research (RSC4Earth), Leipzig University, Leipzig, Germany","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Martin Sudmanns","affiliation":[{"name":"University of Salzburg","address":{"name":"Department of Geoinformatics – Z_GIS, University of Salzburg, Salzburg, Austria","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Dirk Tiede","url":"http://orcid.org/0000-0002-5473-3344","affiliation":[{"name":"University of Salzburg","address":{"name":"Department of Geoinformatics – Z_GIS, University of Salzburg, Salzburg, Austria","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Gonzalo Mateo-García","affiliation":[{"name":"University of Valencia","address":{"name":"Image Processing Laboratory, University of Valencia, Valencia, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Luis Gómez-Chova","url":"http://orcid.org/0000-0003-3924-1269","affiliation":[{"name":"University of Valencia","address":{"name":"Image Processing Laboratory, University of Valencia, Valencia, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/s41597-022-01878-2">
    
    
    <meta name="journal_id" content="41597"/>
    <meta name="dc.title" content="CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2"/>
    <meta name="dc.source" content="Scientific Data 2022 9:1"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2022-12-24"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2022 The Author(s)"/>
    <meta name="dc.rights" content="2022 The Author(s)"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Accurately characterizing clouds and their shadows is a long-standing problem in the Earth Observation community. Recent works showcase the necessity to improve cloud detection methods for imagery acquired by the Sentinel-2 satellites. However, the lack of consensus and transparency in existing reference datasets hampers the benchmarking of current cloud detection methods. Exploiting the analysis-ready data offered by the Copernicus program, we created CloudSEN12, a new multi-temporal global dataset to foster research in cloud and cloud shadow detection. CloudSEN12 has 49,400 image patches, including (1) Sentinel-2 level-1C and level-2A multi-spectral data, (2) Sentinel-1 synthetic aperture radar data, (3) auxiliary remote sensing products, (4) different hand-crafted annotations to label the presence of thick and thin clouds and cloud shadows, and (5) the results from eight state-of-the-art cloud detection algorithms. At present, CloudSEN12 exceeds all previous efforts in terms of annotation richness, scene variability, geographic distribution, metadata complexity, quality control, and number of samples."/>
    <meta name="prism.issn" content="2052-4463"/>
    <meta name="prism.publicationName" content="Scientific Data"/>
    <meta name="prism.publicationDate" content="2022-12-24"/>
    <meta name="prism.volume" content="9"/>
    <meta name="prism.number" content="1"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="1"/>
    <meta name="prism.endingPage" content="17"/>
    <meta name="prism.copyright" content="2022 The Author(s)"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/s41597-022-01878-2"/>
    <meta name="prism.doi" content="doi:10.1038/s41597-022-01878-2"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/s41597-022-01878-2.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/s41597-022-01878-2"/>
    <meta name="citation_journal_title" content="Scientific Data"/>
    <meta name="citation_journal_abbrev" content="Sci Data"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="2052-4463"/>
    <meta name="citation_title" content="CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2"/>
    <meta name="citation_volume" content="9"/>
    <meta name="citation_issue" content="1"/>
    <meta name="citation_online_date" content="2022/12/24"/>
    <meta name="citation_firstpage" content="1"/>
    <meta name="citation_lastpage" content="17"/>
    <meta name="citation_article_type" content="Data Descriptor"/>
    <meta name="citation_fulltext_world_readable" content=""/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/s41597-022-01878-2"/>
    <meta name="DOI" content="10.1038/s41597-022-01878-2"/>
    <meta name="size" content="293095"/>
    <meta name="citation_doi" content="10.1038/s41597-022-01878-2"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/s41597-022-01878-2&amp;api_key="/>
    <meta name="description" content="Accurately characterizing clouds and their shadows is a long-standing problem in the Earth Observation community. Recent works showcase the necessity to improve cloud detection methods for imagery acquired by the Sentinel-2 satellites. However, the lack of consensus and transparency in existing reference datasets hampers the benchmarking of current cloud detection methods. Exploiting the analysis-ready data offered by the Copernicus program, we created CloudSEN12, a new multi-temporal global dataset to foster research in cloud and cloud shadow detection. CloudSEN12 has 49,400 image patches, including (1) Sentinel-2 level-1C and level-2A multi-spectral data, (2) Sentinel-1 synthetic aperture radar data, (3) auxiliary remote sensing products, (4) different hand-crafted annotations to label the presence of thick and thin clouds and cloud shadows, and (5) the results from eight state-of-the-art cloud detection algorithms. At present, CloudSEN12 exceeds all previous efforts in terms of annotation richness, scene variability, geographic distribution, metadata complexity, quality control, and number of samples."/>
    <meta name="dc.creator" content="Aybar, Cesar"/>
    <meta name="dc.creator" content="Ysuhuaylas, Luis"/>
    <meta name="dc.creator" content="Loja, Jhomira"/>
    <meta name="dc.creator" content="Gonzales, Karen"/>
    <meta name="dc.creator" content="Herrera, Fernando"/>
    <meta name="dc.creator" content="Bautista, Lesly"/>
    <meta name="dc.creator" content="Yali, Roy"/>
    <meta name="dc.creator" content="Flores, Angie"/>
    <meta name="dc.creator" content="Diaz, Lissette"/>
    <meta name="dc.creator" content="Cuenca, Nicole"/>
    <meta name="dc.creator" content="Espinoza, Wendy"/>
    <meta name="dc.creator" content="Prudencio, Fernando"/>
    <meta name="dc.creator" content="Llactayo, Valeria"/>
    <meta name="dc.creator" content="Montero, David"/>
    <meta name="dc.creator" content="Sudmanns, Martin"/>
    <meta name="dc.creator" content="Tiede, Dirk"/>
    <meta name="dc.creator" content="Mateo-Garc&#237;a, Gonzalo"/>
    <meta name="dc.creator" content="G&#243;mez-Chova, Luis"/>
    <meta name="dc.subject" content="Atmospheric dynamics"/>
    <meta name="dc.subject" content="Geodynamics"/>
    <meta name="citation_reference" content="citation_journal_title=Earth System Dynamics; citation_title=Earth system data cubes unravel global multivariate dynamics; citation_author=MD Mahecha; citation_volume=11; citation_publication_date=2020; citation_pages=201-234; citation_doi=10.5194/esd-11-201-2020; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Data; citation_title=Earth observation open science: enhancing reproducible science using data cubes; citation_author=G Giuliani, G Camara, B Killough, S Minchin; citation_volume=4; citation_publication_date=2019; citation_pages=4-9; citation_doi=10.3390/data4040147; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=An overview of platforms for big earth observation data management and analysis; citation_author=VC Gomes, GR Queiroz, KR Ferreira; citation_volume=12; citation_publication_date=2020; citation_pages=1-25; citation_doi=10.3390/RS12081253; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Biology; citation_title=Remotely Sensed High-Resolution Global Cloud Dynamics for Predicting Ecosystem and Biodiversity Distributions; citation_author=AM Wilson, W Jetz; citation_volume=14; citation_publication_date=2016; citation_pages=1-20; citation_doi=10.1371/journal.pbio.1002415; citation_id=CR4"/>
    <meta name="citation_reference" content="Ebel, P., Meraner, A., Schmitt, M. &amp; Zhu, X. X. Multi-sensor data fusion for cloud removal in global and all-season sentinel-2 imagery. arXiv 1&#8211;13, 
                  https://doi.org/10.1109/tgrs.2020.3024744
                  
                 (2020)."/>
    <meta name="citation_reference" content="Lynch, D. K., Sassen, K., Starr, D. O. &amp; Stephens, G. Cirrus (Oxford University Press, 2002)."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Geoscience and Remote Sensing; citation_title=Spatially and Temporally Weighted Regression: A Novel Method to Produce Continuous Cloud-Free Landsat Imagery; citation_author=B Chen, B Huang, L Chen, B Xu; citation_volume=55; citation_publication_date=2017; citation_pages=27-37; citation_doi=10.1109/TGRS.2016.2580576; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Scientific Reports; citation_title=Towards global flood mapping onboard low cost satellites with machine learning; citation_author=G Mateo-Garcia; citation_volume=11; citation_publication_date=2021; citation_doi=10.1038/s41598-021-86650-z; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Cirrus clouds that adversely affect Landsat 8 images: What are they and how to detect them?; citation_author=S Qiu, Z Zhu, CE Woodcock; citation_volume=246; citation_publication_date=2020; citation_pages=111884; citation_doi=10.1016/j.rse.2020.111884; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Cloud detection algorithm comparison and validation for operational Landsat data products; citation_author=S Foga; citation_volume=194; citation_publication_date=2017; citation_pages=379-390; citation_doi=10.1016/j.rse.2017.03.026; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Remote Sensing of Environment Fmask 4. 0: Improved cloud and cloud shadow detection in Landsats 4&#8211;8 and Sentinel-2 imagery; citation_author=S Qiu, Z Zhu, B He; citation_volume=231; citation_publication_date=2019; citation_pages=111205; citation_doi=10.1016/j.rse.2019.05.024; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=European Space Agency, (Special Publication) ESA SP; citation_title=Sentinel-2 SEN2COR: L2A processor for users; citation_author=J Louis; citation_volume=SP-740; citation_publication_date=2016; citation_pages=9-13; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Comparison of Cloud Cover Detection Algorithms on Sentinel&#8211;2 Images of the Amazon Tropical Forest; citation_author=AH Sanchez; citation_volume=12; citation_publication_date=2020; citation_pages=1284; citation_doi=10.3390/rs12081284; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Comparison of masking algorithms for sentinel-2 imagery; citation_author=V Zekoll; citation_volume=13; citation_publication_date=2021; citation_pages=1-21; citation_doi=10.3390/rs13010137; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Machine Learning for Cloud Detection of Globally Distributed Sentinel-2 Images; citation_author=R Cilli; citation_volume=12; citation_publication_date=2020; citation_pages=2355; citation_doi=10.3390/rs12152355; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Global evaluation of the suitability of MODIS-Terra detected cloud cover as a proxy for Landsat 7 cloud conditions; citation_author=A Melchiorre, L Boschetti, DP Roy; citation_volume=12; citation_publication_date=2020; citation_pages=1-16; citation_doi=10.3390/rs12020202; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Water Resources Research; citation_title=Cloud Masking for Landsat 8 and MODIS Terra Over Snow-Covered Terrain: Error Analysis and Spectral Similarity Between Snow and Cloud; citation_author=T Stillinger, DA Roberts, NM Collar, J Dozier; citation_volume=55; citation_publication_date=2019; citation_pages=6169-6184; citation_doi=10.1029/2019WR024932; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Geoscience and Remote Sensing Magazine; citation_title=Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources; citation_author=XX Zhu; citation_volume=5; citation_publication_date=2017; citation_pages=8-36; citation_doi=10.1109/MGRS.2017.2762307; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Cloud detection for Landsat imagery by combining the random forest and superpixels extracted via energy-driven sampling segmentation approaches; citation_author=J Wei; citation_volume=248; citation_publication_date=2020; citation_pages=112005; citation_doi=10.1016/j.rse.2020.112005; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Cloud detection for high-resolution satellite imagery using machine learning and multi-feature fusion; citation_author=T Bai, D Li, K Sun, Y Chen, W Li; citation_volume=8; citation_publication_date=2016; citation_pages=1-21; citation_doi=10.3390/rs8090715; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=Advances in Space Research; citation_title=Introducing two Random Forest based methods for cloud detection in remote sensing images; citation_author=N Ghasemian, M Akhoondzadeh; citation_volume=62; citation_publication_date=2018; citation_pages=288-303; citation_doi=10.1016/j.asr.2018.04.030; citation_id=CR21"/>
    <meta name="citation_reference" content="Zupanc, A. Improving Cloud Detection with Machine Learning (2017)."/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Benchmarking deep learning models for cloud detection in landsat-8 and sentinel-2 images; citation_author=D L&#243;pez-Puigdollers, G Mateo-Garc&#237;a, L G&#243;mez-Chova; citation_volume=13; citation_publication_date=2021; citation_pages=1-20; citation_doi=10.3390/rs13050992; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Cloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2; citation_author=S Skakun; citation_volume=274; citation_publication_date=2022; citation_pages=112990; citation_doi=10.1016/j.rse.2022.112990; citation_id=CR24"/>
    <meta name="citation_reference" content="Li, L., Li, X., Jiang, L., Su, X. &amp; Chen, F. A review on deep learning techniques for cloud detection methodologies and challenges. Signal, Image and Video Processing 
                  https://doi.org/10.1007/s11760-021-01885-7
                  
                 (2021)."/>
    <meta name="citation_reference" content="citation_journal_title=Complex &amp; Intelligent Systems; citation_title=Cloud detection methodologies: variants and development&#8211;a review; citation_author=S Mahajan, B Fataniya; citation_volume=6; citation_publication_date=2020; citation_pages=251-261; citation_doi=10.1007/s40747-019-00128-0; citation_id=CR26"/>
    <meta name="citation_reference" content="Hughes, M. J. &amp; Kennedy, R. High-quality cloud masking of landsat 8 imagery using convolutional neural networks. Remote Sensing 11, 
                  https://doi.org/10.3390/rs11212591
                  
                 (2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Ready-to-use methods for the detection of clouds, cirrus, snow, shadow, water and clear sky pixels in Sentinel-2 MSI images; citation_author=A Hollstein, K Segl, L Guanter, M Brell, M Enesco; citation_volume=8; citation_publication_date=2016; citation_pages=1-18; citation_doi=10.3390/rs8080666; citation_id=CR28"/>
    <meta name="citation_reference" content="Mohajerani, S. &amp; Saeedi, P. Cloud-Net: An End-To-End Cloud Detection Algorithm for Landsat 8 Imagery. International Geoscience and Remote Sensing Symposium (IGARSS) 1029&#8211;1032, 
                  https://doi.org/10.1109/IGARSS.2019.8898776
                  
                 (2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Validation of copernicus Sentinel-2 cloud masks obtained from MAJA, Sen2Cor, and FMask processors using reference cloud masks generated with a supervised active learning procedure; citation_author=L Baetens, C Desjardins, O Hagolle; citation_volume=11; citation_publication_date=2019; citation_pages=1-25; citation_doi=10.3390/rs11040433; citation_id=CR30"/>
    <meta name="citation_reference" content="Mohajerani, S. &amp; Saeedi, P. Cloud-Net+: A cloud segmentation CNN for landsat 8 remote sensing imagery optimized with filtered jaccard loss function. arXiv 1&#8211;12 (2020)."/>
    <meta name="citation_reference" content="Francis, A., Mrziglod, J., Sidiropoulos, P. &amp; Muller, J.-P. Sentinel-2 Cloud Mask Catalogue, 
                  https://doi.org/10.5281/zenodo.4172871
                  
                 (2020)."/>
    <meta name="citation_reference" content="Cordts, M. et al. The Cityscapes Dataset for Semantic Urban Scene Understanding. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2016-Decem, 3213&#8211;3223, 
                  https://doi.org/10.1109/CVPR.2016.350
                  
                 (2016)."/>
    <meta name="citation_reference" content="citation_journal_title=arXiv; citation_title=So2Sat LCZ42: A Benchmark Dataset for Global Local Climate Zones Classification; citation_author=XX Zhu; citation_volume=14; citation_publication_date=2019; citation_pages=2-13; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=ISPRS Journal of Photogrammetry and Remote Sensing; citation_title=Cloud removal in Sentinel-2 imagery using a deep residual neural network and SAR-optical data fusion; citation_author=A Meraner, P Ebel, XX Zhu, M Schmitt; citation_volume=166; citation_publication_date=2020; citation_pages=333-346; citation_doi=10.1016/j.isprsjprs.2020.05.013; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=International Geoscience and Remote Sensing Symposium (IGARSS); citation_title=Cloud-GAN: Cloud removal for sentinel-2 imagery using a cyclic consistent generative adversarial networks; citation_author=P Singh, N Komodakis; citation_volume=2018-July; citation_publication_date=2018; citation_pages=1772-1775; citation_doi=10.1109/IGARSS.2018.8519033; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Google Earth Engine: Planetary-scale geospatial analysis for everyone; citation_author=N Gorelick; citation_volume=202; citation_publication_date=2017; citation_pages=18-27; citation_doi=10.1016/j.rse.2017.06.031; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Water Resources Research; citation_title=MERIT Hydro: A High-Resolution Global Hydrography Map Based on Latest Topography Dataset; citation_author=D Yamazaki; citation_volume=55; citation_publication_date=2019; citation_pages=5053-5073; citation_doi=10.1029/2019WR024873; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=High-resolution mapping of global surface water and its long-term changes; citation_author=JF Pekel, A Cottam, N Gorelick, AS Belward; citation_volume=540; citation_publication_date=2016; citation_pages=418-422; citation_doi=10.1038/nature20584; citation_id=CR39"/>
    <meta name="citation_reference" content="Buchhorn, M. et al. Copernicus Global Land Service: Land Cover 100&#8201;m: Collection 3: epoch 2015: Globe (Version V3.0.1). Zenodo 1&#8211;14 (2020)."/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Improvement of the Fmask algorithm for Sentinel-2 images: Separating clouds from bright surfaces based on parallax effects; citation_author=D Frantz, E Ha&#223;, A Uhl, J Stoffels, J Hill; citation_volume=215; citation_publication_date=2018; citation_pages=471-481; citation_doi=10.1016/j.rse.2018.04.046; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=ISPRS Journal of Photogrammetry and Remote Sensing; citation_title=Towards a novel approach for Sentinel-3 synergistic OLCI/SLSTR cloud and cloud shadow detection based on stereo cloud-top height estimation; citation_author=R Fernandez-Moran, L G&#243;mez-Chova, L Alonso, G Mateo-Garc&#237;a, D L&#243;pez-Puigdollers; citation_volume=181; citation_publication_date=2021; citation_pages=238-253; citation_doi=10.1016/j.isprsjprs.2021.09.013; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Investigating ESA Sentinel-2 products&#8217; systematic cloud cover overestimation in very high altitude areas; citation_author=D Tiede, M Sudmanns, H Augustin, A Baraldi; citation_volume=252; citation_publication_date=2021; citation_pages=112163; citation_doi=10.1016/j.rse.2020.112163; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Water Resources Research; citation_title=Canopy Adjustment and Improved Cloud Detection for Remotely Sensed Snow Cover Mapping; citation_author=K Rittger; citation_volume=56; citation_publication_date=2020; citation_pages=1-20; citation_doi=10.1029/2019WR024914; citation_id=CR44"/>
    <meta name="citation_reference" content="Castillo-Navarro, J., Saux, B. L., Boulch, A., Audebert, N. &amp; Lef&#232;vre, S. Semi-Supervised Semantic Segmentation in Earth Observation: The MiniFrance Suite, Dataset Analysis and Multi-task Network Study. arxiv (2020)."/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing of Environment; citation_title=Accurate cloud detection in high-resolution remote sensing imagery by weakly supervised deep learning; citation_author=Y Li; citation_volume=250; citation_publication_date=2020; citation_pages=112045; citation_doi=10.1016/j.rse.2020.112045; citation_id=CR46"/>
    <meta name="citation_reference" content="Valdez, C., Ziefle, M. &amp; Sedlmair, M. A Framework for Studying Biases in Visualization Research. VIS 2017: Dealing with Cognitive Biases in Visualisations (2017)."/>
    <meta name="citation_reference" content="Mrziglod, J. IRIS - Intelligence foR Image Segmentation (2019)."/>
    <meta name="citation_reference" content="Friedman, J. H. Greedy function approximation: a gradient boosting machine. Annals of statistics 1189&#8211;1232 (2001)."/>
    <meta name="citation_reference" content="Ke, G. et al. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In Guyon, I. et al. (eds.) Advances in Neural Information Processing Systems, vol. 30 (2017)."/>
    <meta name="citation_reference" content="citation_journal_title=Atmospheric Measurement Techniques; citation_title=Coupling sky images with radiative transfer models: a new method to estimate cloud optical depth; citation_author=FA Mejia; citation_volume=9; citation_publication_date=2016; citation_pages=4151-4165; citation_doi=10.5194/amt-9-4151-2016; citation_id=CR51"/>
    <meta name="citation_reference" content="citation_journal_title=ISPRS Journal of Photogrammetry and Remote Sensing; citation_title=Transferring deep learning models for cloud detection between Landsat-8 and Proba-V; citation_author=G Mateo-Garc&#237;a, V Laparra, D L&#243;pez-Puigdollers, L G&#243;mez-Chova; citation_volume=160; citation_publication_date=2020; citation_pages=1-17; citation_doi=10.1016/j.isprsjprs.2019.11.024; citation_id=CR52"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing; citation_title=Cross-Sensor Adversarial Domain Adaptation of Landsat-8 and Proba-V Images for Cloud Detection; citation_author=G Mateo-Garc&#237;a, V Laparra, D L&#243;pez-Puigdollers, L G&#243;mez-Chova; citation_volume=14; citation_publication_date=2021; citation_pages=747-761; citation_doi=10.1109/JSTARS.2020.3031741; citation_id=CR53"/>
    <meta name="citation_reference" content="Domnich, M. et al. KappaMask: Ai-based cloudmask processor for sentinel-2. Remote Sensing 13, 
                  https://doi.org/10.3390/rs13204100
                  
                 (2021)."/>
    <meta name="citation_reference" content="citation_journal_title=Methods in Ecology and Evolution; citation_title=blockCV: An r package for generating spatially or environmentally separated folds for k-fold cross-validation of species distribution models; citation_author=R Valavi, J Elith, JJ Lahoz-Monfort, G Guillera-Arroita; citation_volume=10; citation_publication_date=2019; citation_pages=225-232; citation_doi=10.1111/2041-210X.13107; citation_id=CR55"/>
    <meta name="citation_reference" content="citation_journal_title=Ecography; citation_title=Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure; citation_author=DR Roberts; citation_volume=40; citation_publication_date=2017; citation_pages=913-929; citation_doi=10.1111/ecog.02881; citation_id=CR56"/>
    <meta name="citation_reference" content="Luis, C. et al. CloudSEN12 - a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2.&#160;Science Data Bank 
                  https://doi.org/10.57760/sciencedb.06669
                  
                 (2022)."/>
    <meta name="citation_reference" content="citation_journal_title=Geomatics; citation_title=Cloud optimized raster encoding (core): A web-native streamable format for large environmental time series; citation_author=I Iosifescu Enescu; citation_volume=1; citation_publication_date=2021; citation_pages=369-382; citation_doi=10.3390/geomatics1030021; citation_id=CR58"/>
    <meta name="citation_reference" content="Ronneberger, O., Fischer, P. &amp; Brox, T. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention, 234&#8211;241 (Springer, 2015)."/>
    <meta name="citation_reference" content="Sandler, M., Howard, A., Zhu, M., Zhmoginov, A. &amp; Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 4510&#8211;4520 (2018)."/>
    <meta name="citation_reference" content="Paszke, A. et al. Pytorch: An imperative style, high-performance deep learning library. In Wallach, H. et al. (eds.) Advances in Neural Information Processing Systems 32, 8024&#8211;8035 (Curran Associates, Inc., 2019)."/>
    <meta name="citation_reference" content="European Space Agency. CEOS-WGCV ACIX II CMIX Atmospheric Correction Inter-comparison Exercise Cloud Masking Inter-comparison Exercise 2nd workshop (2019). Online; accessed 14 October 2021."/>
    <meta name="citation_reference" content="Paperin, M., Wevers, J., Stelzer, K. &amp; Brockmann, C. PixBox Sentinel-2 pixel collection for CMIX. Zenodo 
                  https://doi.org/10.5281/zenodo.5036991
                  
                 (2021)."/>
    <meta name="citation_reference" content="citation_journal_title=ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences; citation_title=SAR-sharpening in the Kennaugh framework applied to the fusion of multi-modal SAR and optical images; citation_author=A Schmitt, A Wendleder; citation_volume=4; citation_publication_date=2018; citation_pages=133-140; citation_doi=10.5194/isprs-annals-IV-1-133-2018; citation_id=CR64"/>
    <meta name="citation_reference" content="citation_journal_title=International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives; citation_title=Colorizing sentinel-1 SAR images using a variational autoencoder conditioned on Sentinel-2 imagery; citation_author=M Schmitt, LH Hughes, M K&#246;rner, XX Zhu; citation_volume=42; citation_publication_date=2018; citation_pages=1045-1051; citation_doi=10.5194/isprs-archives-XLII-2-1045-2018; citation_id=CR65"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Geoscience and Remote Sensing Letters; citation_title=Identifying Corresponding Patches in SAR and Optical Images with a Pseudo-Siamese CNN; citation_author=LH Hughes, M Schmitt, L Mou, Y Wang, XX Zhu; citation_volume=15; citation_publication_date=2018; citation_pages=784-788; citation_doi=10.1109/LGRS.2018.2799232; citation_id=CR66"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Open Source Software; citation_title=rgee: An R package for interacting with Google Earth Engine; citation_author=C Aybar, Q Wu, L Bautista, R Yali, A Barja; citation_volume=5; citation_publication_date=2020; citation_pages=2272; citation_doi=10.21105/joss.02272; citation_id=CR67"/>
    <meta name="citation_reference" content="citation_journal_title=R Journal; citation_title=Simple features for R: Standardized support for spatial vector data; citation_author=E Pebesma; citation_volume=10; citation_publication_date=2018; citation_pages=439-446; citation_doi=10.32614/rj-2018-009; citation_id=CR68"/>
    <meta name="citation_reference" content="Hijmans, R. J. et al. Package &#8216;raster&#8217;. R package 734 (2015)."/>
    <meta name="citation_reference" content="Pebesma, E. stars: Spatiotemporal arrays, raster and vector data cubes. R package version 0.4&#8211;1 ed2020 
                  https://CRAN.R-project.org/package=stars
                  
                 (2020)."/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Array programming with numpy; citation_author=CR Harris; citation_volume=585; citation_publication_date=2020; citation_pages=357-362; citation_doi=10.1038/s41586-020-2649-2; citation_id=CR71"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of statistical software; citation_title=Dates and times made easy with lubridate; citation_author=G Grolemund, H Wickham; citation_volume=40; citation_publication_date=2011; citation_pages=1-25; citation_doi=10.18637/jss.v040.i03; citation_id=CR72"/>
    <meta name="citation_reference" content="citation_journal_title=R package version; citation_title=reticulate: Interface to python; citation_author=K Ushey; citation_volume=1; citation_publication_date=2020; citation_pages=16; citation_id=CR73"/>
    <meta name="citation_reference" content="Wickham, H., Francios, R., Henry, L. &amp; Muller, K. Dplyr: A fast, consistent tool for working with data frame like objects, both in memory and out of memory. R package version 0.7 6 (2014)."/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Statistical Software; citation_title=tmap: Thematic maps in r; citation_author=M Tennekes; citation_volume=84; citation_publication_date=2018; citation_pages=1-39; citation_doi=10.18637/jss.v084.i06; citation_id=CR75"/>
    <meta name="citation_reference" content="Ooms, J. magick: Advanced graphics and image-processing in r. R package version 2 (2020)."/>
    <meta name="citation_reference" content="Wilke, C. O. ggridges: ridgeline plots in &#8216;ggplot2&#8217;. R package version 0.5 1 (2018)."/>
    <meta name="citation_reference" content="citation_journal_title=Wiley interdisciplinary reviews: computational statistics; citation_title=ggplot2; citation_author=H Wickham; citation_volume=3; citation_publication_date=2011; citation_pages=180-185; citation_doi=10.1002/wics.147; citation_id=CR78"/>
    <meta name="citation_reference" content="citation_journal_title=Remote Sensing; citation_title=Automated detection of cloud and cloud shadow in single-date Landsat imagery using neural networks and spatial post-processing; citation_author=MJ Hughes, DJ Hayes; citation_volume=6; citation_publication_date=2014; citation_pages=4907-4926; citation_doi=10.3390/rs6064907; citation_id=CR79"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Geoscience and Remote Sensing Letters; citation_title=Self-attentive generative adversarial network for cloud detection in high resolution remote sensing images; citation_author=Z Wu, J Li, Y Wang, Z Hu, M Molinier; citation_volume=17; citation_publication_date=2019; citation_pages=1792-1796; citation_doi=10.1109/LGRS.2019.2955071; citation_id=CR80"/>
    <meta name="citation_author" content="Aybar, Cesar"/>
    <meta name="citation_author_institution" content="Image Processing Laboratory, University of Valencia, Valencia, Spain"/>
    <meta name="citation_author_institution" content="Department of Geoinformatics &#8211; Z_GIS, University of Salzburg, Salzburg, Austria"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Ysuhuaylas, Luis"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Loja, Jhomira"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Gonzales, Karen"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Herrera, Fernando"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Bautista, Lesly"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Yali, Roy"/>
    <meta name="citation_author_institution" content="Research Group on Artificial Intelligence, Pontifical Catholic University of Peru, Lima, Peru"/>
    <meta name="citation_author" content="Flores, Angie"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Diaz, Lissette"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Cuenca, Nicole"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Espinoza, Wendy"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Prudencio, Fernando"/>
    <meta name="citation_author_institution" content="Sub-directorate of Atmospheric and Hydrospheric Sciences, Geophysical Institute of Peru, Lima, Peru"/>
    <meta name="citation_author" content="Llactayo, Valeria"/>
    <meta name="citation_author_institution" content="High Mountain Ecosystem Research Group, National University of San Marcos, Lima, Peru"/>
    <meta name="citation_author" content="Montero, David"/>
    <meta name="citation_author_institution" content="Remote Sensing Centre for Earth Systems Research (RSC4Earth), Leipzig University, Leipzig, Germany"/>
    <meta name="citation_author" content="Sudmanns, Martin"/>
    <meta name="citation_author_institution" content="Department of Geoinformatics &#8211; Z_GIS, University of Salzburg, Salzburg, Austria"/>
    <meta name="citation_author" content="Tiede, Dirk"/>
    <meta name="citation_author_institution" content="Department of Geoinformatics &#8211; Z_GIS, University of Salzburg, Salzburg, Austria"/>
    <meta name="citation_author" content="Mateo-Garc&#237;a, Gonzalo"/>
    <meta name="citation_author_institution" content="Image Processing Laboratory, University of Valencia, Valencia, Spain"/>
    <meta name="citation_author" content="G&#243;mez-Chova, Luis"/>
    <meta name="citation_author_institution" content="Image Processing Laboratory, University of Valencia, Valencia, Spain"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@scientificdata"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2"/>
    <meta name="twitter:description" content="Scientific Data - CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2"/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig1_HTML.png"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/s41597-022-01878-2"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2 - Scientific Data"/>
    <meta property="og:description" content="Measurement(s) clouds extension Technology Type(s) machine learning with photo-interpretation. Factor Type(s) Copernicus Sentinel-2 images Sample Characteristic - Environment geosphere Sample Characteristic - Location all the world"/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig1_HTML.png"/>
    

    <script>
        window.eligibleForRa21 = 'false'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/sdata.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=s41597-022-01878-2;doi=10.1038/s41597-022-01878-2;subjmeta=106,210,35,445,704,823;kwrd=Atmospheric+dynamics,Geodynamics">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/sdata.nature.com/article&amp;sz=728x90&amp;c=-937179895&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41597-022-01878-2%26doi%3D10.1038/s41597-022-01878-2%26subjmeta%3D106,210,35,445,704,823%26kwrd%3DAtmospheric+dynamics,Geodynamics">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/sdata.nature.com/article&amp;sz=728x90&amp;c=-937179895&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41597-022-01878-2%26doi%3D10.1038/s41597-022-01878-2%26subjmeta%3D106,210,35,445,704,823%26kwrd%3DAtmospheric+dynamics,Geodynamics"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#3598c2">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/sdata"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/sdata/header-87021870c315c48063927b82055c12bc.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/sdata/header-87021870c315c48063927b82055c12bc.svg" height="32" alt="Scientific Data">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41597-022-01878-2'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D329%26journal-link%3Dhttps%253A%252F%252Fwww.nature.com%252Fsdata%252F"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/sdata.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/sdata" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:scientific data"><span itemprop="name">scientific data</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/sdata/articles?type&#x3D;data-descriptor" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:data descriptors"><span itemprop="name">data descriptors</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41597-022-01878-2.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
                <div class="c-pdf-button__container u-mb-16 u-hide-at-lg js-context-bar-sticky-point-mobile">
                    <div class="c-pdf-container">
                        
                            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41597-022-01878-2.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                        
                    </div>
                </div>
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Data Descriptor</li>
    
        <li class="c-article-identifiers__item">
            <a href="https://www.springernature.com/gp/open-research/about/the-fundamentals-of-open-access-and-open-research" data-track="click" data-track-action="open access" data-track-label="link" class="u-color-open-access" data-test="open-access">Open access</a>
        </li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2022-12-24">24 December 2022</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Cesar-Aybar-Aff1-Aff2-Aff3" data-author-popup="auth-Cesar-Aybar-Aff1-Aff2-Aff3" data-author-search="Aybar, Cesar" data-corresp-id="c1">Cesar Aybar<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-2745-9535"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-2745-9535</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Luis-Ysuhuaylas-Aff3" data-author-popup="auth-Luis-Ysuhuaylas-Aff3" data-author-search="Ysuhuaylas, Luis">Luis Ysuhuaylas</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0001-9819-703X"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-9819-703X</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jhomira-Loja-Aff3" data-author-popup="auth-Jhomira-Loja-Aff3" data-author-search="Loja, Jhomira">Jhomira Loja</a><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Karen-Gonzales-Aff3" data-author-popup="auth-Karen-Gonzales-Aff3" data-author-search="Gonzales, Karen">Karen Gonzales</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0001-7634-684X"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-7634-684X</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Fernando-Herrera-Aff3" data-author-popup="auth-Fernando-Herrera-Aff3" data-author-search="Herrera, Fernando">Fernando Herrera</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-8545-0806"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-8545-0806</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Lesly-Bautista-Aff3" data-author-popup="auth-Lesly-Bautista-Aff3" data-author-search="Bautista, Lesly">Lesly Bautista</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-3523-8687"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-3523-8687</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Roy-Yali-Aff4" data-author-popup="auth-Roy-Yali-Aff4" data-author-search="Yali, Roy">Roy Yali</a><sup class="u-js-hide"><a href="#Aff4">4</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Angie-Flores-Aff3" data-author-popup="auth-Angie-Flores-Aff3" data-author-search="Flores, Angie">Angie Flores</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-5294-9635"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-5294-9635</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Lissette-Diaz-Aff3" data-author-popup="auth-Lissette-Diaz-Aff3" data-author-search="Diaz, Lissette">Lissette Diaz</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-3789-0927"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-3789-0927</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Nicole-Cuenca-Aff3" data-author-popup="auth-Nicole-Cuenca-Aff3" data-author-search="Cuenca, Nicole">Nicole Cuenca</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-9046-7987"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-9046-7987</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Wendy-Espinoza-Aff3" data-author-popup="auth-Wendy-Espinoza-Aff3" data-author-search="Espinoza, Wendy">Wendy Espinoza</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-6061-814X"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-6061-814X</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Fernando-Prudencio-Aff5" data-author-popup="auth-Fernando-Prudencio-Aff5" data-author-search="Prudencio, Fernando">Fernando Prudencio</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-1169-3618"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-1169-3618</a></span><sup class="u-js-hide"><a href="#Aff5">5</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Valeria-Llactayo-Aff3" data-author-popup="auth-Valeria-Llactayo-Aff3" data-author-search="Llactayo, Valeria">Valeria Llactayo</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-3267-7775"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-3267-7775</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-David-Montero-Aff6" data-author-popup="auth-David-Montero-Aff6" data-author-search="Montero, David">David Montero</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-9010-3286"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-9010-3286</a></span><sup class="u-js-hide"><a href="#Aff6">6</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Martin-Sudmanns-Aff2" data-author-popup="auth-Martin-Sudmanns-Aff2" data-author-search="Sudmanns, Martin">Martin Sudmanns</a><sup class="u-js-hide"><a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Dirk-Tiede-Aff2" data-author-popup="auth-Dirk-Tiede-Aff2" data-author-search="Tiede, Dirk">Dirk Tiede</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-5473-3344"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-5473-3344</a></span><sup class="u-js-hide"><a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Gonzalo-Mateo_Garc_a-Aff1" data-author-popup="auth-Gonzalo-Mateo_Garc_a-Aff1" data-author-search="Mateo-García, Gonzalo">Gonzalo Mateo-García</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 18 authors for this article" title="Show all 18 authors for this article">…</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Luis-G_mez_Chova-Aff1" data-author-popup="auth-Luis-G_mez_Chova-Aff1" data-author-search="Gómez-Chova, Luis">Luis Gómez-Chova</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-3924-1269"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-3924-1269</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup> </li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/sdata" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Scientific Data</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 9</b>, Article number: <span data-test="article-number">782</span> (<span data-test="article-publication-year">2022</span>)
            <a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">6123 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">10 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">17 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/s41597-022-01878-2/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/atmospheric-dynamics" data-track="click" data-track-action="view subject" data-track-label="link">Atmospheric dynamics</a></li><li class="c-article-subject-list__subject"><a href="/subjects/geodynamics" data-track="click" data-track-action="view subject" data-track-label="link">Geodynamics</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Accurately characterizing clouds and their shadows is a long-standing problem in the Earth Observation community. Recent works showcase the necessity to improve cloud detection methods for imagery acquired by the Sentinel-2 satellites. However, the lack of consensus and transparency in existing reference datasets hampers the benchmarking of current cloud detection methods. Exploiting the analysis-ready data offered by the Copernicus program, we created CloudSEN12, a new multi-temporal global dataset to foster research in cloud and cloud shadow detection. CloudSEN12 has 49,400 image patches, including (1) Sentinel-2 level-1C and level-2A multi-spectral data, (2) Sentinel-1 synthetic aperture radar data, (3) auxiliary remote sensing products, (4) different hand-crafted annotations to label the presence of thick and thin clouds and cloud shadows, and (5) the results from eight state-of-the-art cloud detection algorithms. At present, CloudSEN12 exceeds all previous efforts in terms of annotation richness, scene variability, geographic distribution, metadata complexity, quality control, and number of samples.</p></div></div></section><section lang="en"><div class="c-article-section" id="Abs2-section"><div class="c-article-section__content" id="Abs2-content"><div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><tbody><tr><td class="u-text-left "><p>Measurement(s)</p></td><td class="u-text-left "><p>clouds extension</p></td></tr><tr><td class="u-text-left "><p>Technology Type(s)</p></td><td class="u-text-left "><p>machine learning with photo-interpretation.</p></td></tr><tr><td class="u-text-left "><p>Factor Type(s)</p></td><td class="u-text-left "><p>Copernicus Sentinel-2 images</p></td></tr><tr><td class="u-text-left "><p>Sample Characteristic - Environment</p></td><td class="u-text-left "><p>geosphere</p></td></tr><tr><td class="u-text-left "><p>Sample Characteristic - Location</p></td><td class="u-text-left "><p>all the world</p></td></tr></tbody></table></div></div></div></div></div></section>

            <noscript>
                
            </noscript>

            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41597-022-01674-y/MediaObjects/41597_2022_1674_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41597-022-01674-y?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41597-022-01674-y">CatLC: Catalonia Multiresolution Land Cover Dataset
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">08 September 2022</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Carlos García, Oscar Mora, … Jordi Vitrià</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41597-022-01269-7/MediaObjects/41597_2022_1269_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41597-022-01269-7?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41597-022-01269-7">MASCDB, a database of images, descriptors and microphysical properties of individual snowflakes in free fall
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">03 May 2022</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Jacopo Grazioli, Gionata Ghiggi, … Alexis Berne</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-023-46808-3/MediaObjects/41598_2023_46808_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41598-023-46808-3?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41598-023-46808-3">Dehazing in hyperspectral images: the GRANHHADA database
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">13 November 2023</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Sol Fernández Carvelo, Miguel Ángel Martínez Domingo, … Javier Hernández Andrés</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1713014455,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Background &amp; Summary"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Background &amp; Summary</h2><div class="c-article-section__content" id="Sec1-content"><p>We are in the midst of an exciting new era of Earth observation (EO), wherein Analysis Ready Data (ARD)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Mahecha, M. D. et al. Earth system data cubes unravel global multivariate dynamics. Earth System Dynamics 11, 201–234, &#xA;                  https://doi.org/10.5194/esd-11-201-2020&#xA;                  &#xA;                 (2020)." href="#ref-CR1" id="ref-link-section-d75612378e681">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Giuliani, G., Camara, G., Killough, B. &amp; Minchin, S. Earth observation open science: enhancing reproducible science using data cubes. Data 4, 4–9, &#xA;                  https://doi.org/10.3390/data4040147&#xA;                  &#xA;                 (2019)." href="#ref-CR2" id="ref-link-section-d75612378e681_1">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Gomes, V. C., Queiroz, G. R. &amp; Ferreira, K. R. An overview of platforms for big earth observation data management and analysis. Remote Sensing 12, 1–25, &#xA;                  https://doi.org/10.3390/RS12081253&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR3" id="ref-link-section-d75612378e684">3</a></sup> products derived from big optical satellite imagery catalogs permit direct analyses without laborious pre-processing. Unfortunately, many of these products are contaminated by clouds<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Wilson, A. M. &amp; Jetz, W. Remotely Sensed High-Resolution Global Cloud Dynamics for Predicting Ecosystem and Biodiversity Distributions. PLoS Biology 14, 1–20, &#xA;                  https://doi.org/10.1371/journal.pbio.1002415&#xA;                  &#xA;                 (2016)." href="/articles/s41597-022-01878-2#ref-CR4" id="ref-link-section-d75612378e688">4</a></sup> and their corresponding shadows, altering the surface reflectance values and hampering their operational exploitation at large scales. For most of the applications exploiting ARD, cloud and cloud-shadow pixels need to be removed prior to further analyses, i.e. masked out, to avoid distortions in the results.</p><p>Improving the accuracy of existing cloud detection (CD) algorithms used in current ARD products is a pressing need for the EO community regarding optical sensors such as Sentinel-2. Ideally, CD algorithms would classify pixels into clear, cloud shadow, thin cloud, and thick cloud. Splitting clouds into two subclasses allows downstream applications to design different strategies to treat cloud contamination. On the one hand, thick clouds entirely block the surface’s view, reflecting most of the light coming from the sun and generating gaps impossible to retrieve using optical sensors data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Ebel, P., Meraner, A., Schmitt, M. &amp; Zhu, X. X. Multi-sensor data fusion for cloud removal in global and all-season sentinel-2 imagery. arXiv 1–13, &#xA;                  https://doi.org/10.1109/tgrs.2020.3024744&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR5" id="ref-link-section-d75612378e695">5</a></sup>. On the other hand, thin clouds do not reflect all the sunlight allowing to observe a distorted view of the surface<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Lynch, D. K., Sassen, K., Starr, D. O. &amp; Stephens, G. Cirrus (Oxford University Press, 2002)." href="/articles/s41597-022-01878-2#ref-CR6" id="ref-link-section-d75612378e699">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Chen, B., Huang, B., Chen, L. &amp; Xu, B. Spatially and Temporally Weighted Regression: A Novel Method to Produce Continuous Cloud-Free Landsat Imagery. IEEE Transactions on Geoscience and Remote Sensing 55, 27–37, &#xA;                  https://doi.org/10.1109/TGRS.2016.2580576&#xA;                  &#xA;                 (2017)." href="/articles/s41597-022-01878-2#ref-CR7" id="ref-link-section-d75612378e702">7</a></sup>. For some applications, such as object detection or disaster response<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Mateo-Garcia, G. et al. Towards global flood mapping onboard low cost satellites with machine learning. Scientific Reports 11, 7249, &#xA;                  https://doi.org/10.1038/s41598-021-86650-z&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR8" id="ref-link-section-d75612378e706">8</a></sup>, images contaminated with thin clouds are still helpful. Therefore, distinguishing between thick and thin clouds is also a critical first step toward optical data exploitation. Nevertheless, it is worth noting that there is no overall consensus on quantitative approaches delimiting when one class begins and the other ends; thus, it is so far inherently subjective to the image interpreter<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Qiu, S., Zhu, Z. &amp; Woodcock, C. E. Cirrus clouds that adversely affect Landsat 8 images: What are they and how to detect them? Remote Sensing of Environment 246, 111884, &#xA;                  https://doi.org/10.1016/j.rse.2020.111884&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR9" id="ref-link-section-d75612378e710">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Foga, S. et al. Cloud detection algorithm comparison and validation for operational Landsat data products. Remote Sensing of Environment 194, 379–390, &#xA;                  https://doi.org/10.1016/j.rse.2017.03.026&#xA;                  &#xA;                 (2017)." href="/articles/s41597-022-01878-2#ref-CR10" id="ref-link-section-d75612378e713">10</a></sup>.</p><p>Methodologies for CD can be classified into two main categories: knowledge-driven (KD) and data-driven (DD). KD category emphasizes the logical sense connected with physical foundations. For instance, the Function of mask (Fmask)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Qiu, S., Zhu, Z. &amp; He, B. Remote Sensing of Environment Fmask 4. 0: Improved cloud and cloud shadow detection in Landsats 4–8 and Sentinel-2 imagery. Remote Sensing of Environment 231, 111205, &#xA;                  https://doi.org/10.1016/j.rse.2019.05.024&#xA;                  &#xA;                 (2019)." href="/articles/s41597-022-01878-2#ref-CR11" id="ref-link-section-d75612378e720">11</a></sup> and Sen2Cor<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Louis, J. et al. Sentinel-2 SEN2COR: L2A processor for users. European Space Agency, (Special Publication) ESA SP SP-740, 9–13 (2016)." href="/articles/s41597-022-01878-2#ref-CR12" id="ref-link-section-d75612378e724">12</a></sup> use a set of physical rules formulated on spectral and contextual features to distinguish clouds against water or land. Overall, KD algorithms achieve accurate results, and good generalization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Sanchez, A. H. et al. Comparison of Cloud Cover Detection Algorithms on Sentinel–2 Images of the Amazon Tropical Forest. Remote Sensing 12, 1284, &#xA;                  https://doi.org/10.3390/rs12081284&#xA;                  &#xA;                 (2020)." href="#ref-CR13" id="ref-link-section-d75612378e728">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Zekoll, V. et al. Comparison of masking algorithms for sentinel-2 imagery. Remote Sensing 13, 1–21, &#xA;                  https://doi.org/10.3390/rs13010137&#xA;                  &#xA;                 (2021)." href="#ref-CR14" id="ref-link-section-d75612378e728_1">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Cilli, R. et al. Machine Learning for Cloud Detection of Globally Distributed Sentinel-2 Images. Remote Sensing 12, 2355, &#xA;                  https://doi.org/10.3390/rs12152355&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR15" id="ref-link-section-d75612378e731">15</a></sup>. However, it is well-known that they have problems associated with thin cloud omission and non-cloud object commission, frequently at cloud edges and under surfaces with a smooth texture or high reflectance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Melchiorre, A., Boschetti, L. &amp; Roy, D. P. Global evaluation of the suitability of MODIS-Terra detected cloud cover as a proxy for Landsat 7 cloud conditions. Remote Sensing 12, 1–16, &#xA;                  https://doi.org/10.3390/rs12020202&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR16" id="ref-link-section-d75612378e735">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Stillinger, T., Roberts, D. A., Collar, N. M. &amp; Dozier, J. Cloud Masking for Landsat 8 and MODIS Terra Over Snow-Covered Terrain: Error Analysis and Spectral Similarity Between Snow and Cloud. Water Resources Research 55, 6169–6184, &#xA;                  https://doi.org/10.1029/2019WR024932&#xA;                  &#xA;                 (2019)." href="/articles/s41597-022-01878-2#ref-CR17" id="ref-link-section-d75612378e738">17</a></sup>.</p><p>In recent years, supervised data-driven strategies, trained in large manually annotated datasets, have grown notoriety in remote sensing thanks to the success of classical machine learning (ML) and deep learning (DL) techniques<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Zhu, X. X. et al. Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources. IEEE Geoscience and Remote Sensing Magazine 5, 8–36, &#xA;                  https://doi.org/10.1109/MGRS.2017.2762307&#xA;                  &#xA;                 (2017)." href="/articles/s41597-022-01878-2#ref-CR18" id="ref-link-section-d75612378e745">18</a></sup>. Among multiple noteworthy ML precedents<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wei, J. et al. Cloud detection for Landsat imagery by combining the random forest and superpixels extracted via energy-driven sampling segmentation approaches. Remote Sensing of Environment 248, 112005, &#xA;                  https://doi.org/10.1016/j.rse.2020.112005&#xA;                  &#xA;                 (2020)." href="#ref-CR19" id="ref-link-section-d75612378e749">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bai, T., Li, D., Sun, K., Chen, Y. &amp; Li, W. Cloud detection for high-resolution satellite imagery using machine learning and multi-feature fusion. Remote Sensing 8, 1–21, &#xA;                  https://doi.org/10.3390/rs8090715&#xA;                  &#xA;                 (2016)." href="#ref-CR20" id="ref-link-section-d75612378e749_1">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Ghasemian, N. &amp; Akhoondzadeh, M. Introducing two Random Forest based methods for cloud detection in remote sensing images. Advances in Space Research 62, 288–303, &#xA;                  https://doi.org/10.1016/j.asr.2018.04.030&#xA;                  &#xA;                 (2018)." href="/articles/s41597-022-01878-2#ref-CR21" id="ref-link-section-d75612378e752">21</a></sup> in cloud detection, Sentinel Hub’s s2cloudless<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Zupanc, A. Improving Cloud Detection with Machine Learning (2017)." href="/articles/s41597-022-01878-2#ref-CR22" id="ref-link-section-d75612378e756">22</a></sup> is the most extensively used due to its low computational requirements and lightweight design. Nonetheless, when evaluated in certain particular regions, such as tropical forests, s2cloudless falls short of <i>state-of-the-art</i> KD cloud detectors<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Sanchez, A. H. et al. Comparison of Cloud Cover Detection Algorithms on Sentinel–2 Images of the Amazon Tropical Forest. Remote Sensing 12, 1284, &#xA;                  https://doi.org/10.3390/rs12081284&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR13" id="ref-link-section-d75612378e763">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="López-Puigdollers, D., Mateo-García, G. &amp; Gómez-Chova, L. Benchmarking deep learning models for cloud detection in landsat-8 and sentinel-2 images. Remote Sensing 13, 1–20, &#xA;                  https://doi.org/10.3390/rs13050992&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR23" id="ref-link-section-d75612378e766">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Skakun, S. et al. Cloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2. Remote Sensing of Environment 274, 112990, &#xA;                  https://doi.org/10.1016/j.rse.2022.112990&#xA;                  &#xA;                 (2022)." href="/articles/s41597-022-01878-2#ref-CR24" id="ref-link-section-d75612378e769">24</a></sup>. Meanwhile, DL has proven to be more effective on CD compared to more classical ML<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Li, L., Li, X., Jiang, L., Su, X. &amp; Chen, F. A review on deep learning techniques for cloud detection methodologies and challenges. Signal, Image and Video Processing &#xA;                  https://doi.org/10.1007/s11760-021-01885-7&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR25" id="ref-link-section-d75612378e774">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Mahajan, S. &amp; Fataniya, B. Cloud detection methodologies: variants and development–a review. Complex &amp; Intelligent Systems 6, 251–261, &#xA;                  https://doi.org/10.1007/s40747-019-00128-0&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR26" id="ref-link-section-d75612378e777">26</a></sup>, although it is subjected to the exigency of pixel-level annotation.</p><p>The recent progress in DL-based cloud semantic segmentation in Sentinel-2 can be attributed to the proliferation of public CD datasets such as SPARCS<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Hughes, M. J. &amp; Kennedy, R. High-quality cloud masking of landsat 8 imagery using convolutional neural networks. Remote Sensing 11, &#xA;                  https://doi.org/10.3390/rs11212591&#xA;                  &#xA;                 (2019)." href="/articles/s41597-022-01878-2#ref-CR27" id="ref-link-section-d75612378e785">27</a></sup>, S2-Hollstein<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Hollstein, A., Segl, K., Guanter, L., Brell, M. &amp; Enesco, M. Ready-to-use methods for the detection of clouds, cirrus, snow, shadow, water and clear sky pixels in Sentinel-2 MSI images. Remote Sensing 8, 1–18, &#xA;                  https://doi.org/10.3390/rs8080666&#xA;                  &#xA;                 (2016)." href="/articles/s41597-022-01878-2#ref-CR28" id="ref-link-section-d75612378e789">28</a></sup>, Biome 8<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Foga, S. et al. Cloud detection algorithm comparison and validation for operational Landsat data products. Remote Sensing of Environment 194, 379–390, &#xA;                  https://doi.org/10.1016/j.rse.2017.03.026&#xA;                  &#xA;                 (2017)." href="/articles/s41597-022-01878-2#ref-CR10" id="ref-link-section-d75612378e793">10</a></sup>, 38-cloud<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Mohajerani, S. &amp; Saeedi, P. Cloud-Net: An End-To-End Cloud Detection Algorithm for Landsat 8 Imagery. International Geoscience and Remote Sensing Symposium (IGARSS) 1029–1032, &#xA;                  https://doi.org/10.1109/IGARSS.2019.8898776&#xA;                  &#xA;                 (2019)." href="/articles/s41597-022-01878-2#ref-CR29" id="ref-link-section-d75612378e797">29</a></sup>, CESBIO<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Baetens, L., Desjardins, C. &amp; Hagolle, O. Validation of copernicus Sentinel-2 cloud masks obtained from MAJA, Sen2Cor, and FMask processors using reference cloud masks generated with a supervised active learning procedure. Remote Sensing 11, 1–25, &#xA;                  https://doi.org/10.3390/rs11040433&#xA;                  &#xA;                 (2019)." href="/articles/s41597-022-01878-2#ref-CR30" id="ref-link-section-d75612378e801">30</a></sup>, 95-Cloud<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Mohajerani, S. &amp; Saeedi, P. Cloud-Net+: A cloud segmentation CNN for landsat 8 remote sensing imagery optimized with filtered jaccard loss function. arXiv 1–12 (2020)." href="/articles/s41597-022-01878-2#ref-CR31" id="ref-link-section-d75612378e806">31</a></sup>, and CloudCatalogue<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Francis, A., Mrziglod, J., Sidiropoulos, P. &amp; Muller, J.-P. Sentinel-2 Cloud Mask Catalogue, &#xA;                  https://doi.org/10.5281/zenodo.4172871&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR32" id="ref-link-section-d75612378e810">32</a></sup>. Nonetheless, these datasets have some well-known shortcomings, including the absence of a temporal component, a lack of thin clouds or cloud shadows labels, a high degree of imbalance between cloud and non-cloud classes, and a relatively small size joined with geographical bias (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab1">1</a> for the current characteristics/limitations of each of those datasets). Furthermore, their quality control process is not always properly described and their development remains somehow unclear. Additionally, there is a lack of consensus on manual annotation protocols and cloud semantic classes definition, which makes inter-dataset comparison problematic, particularly under pixels where class transitions occur. These flaws hinder the natural transition to global DL cloud classifiers and the application of new-fashioned geographically-aware algorithms<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Sanchez, A. H. et al. Comparison of Cloud Cover Detection Algorithms on Sentinel–2 Images of the Amazon Tropical Forest. Remote Sensing 12, 1284, &#xA;                  https://doi.org/10.3390/rs12081284&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR13" id="ref-link-section-d75612378e817">13</a></sup>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Summary of publicly available CD datasets in comparison to CloudSEN12. An asterisk represents that the dataset does not distinguish the specific class.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41597-022-01878-2/tables/2" aria-label="Full size table 2"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Inspired by the CityScapes dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Cordts, M. et al. The Cityscapes Dataset for Semantic Urban Scene Understanding. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2016-Decem, 3213–3223, &#xA;                  https://doi.org/10.1109/CVPR.2016.350&#xA;                  &#xA;                 (2016)." href="/articles/s41597-022-01878-2#ref-CR33" id="ref-link-section-d75612378e1521">33</a></sup>, we created and released CloudSEN12, a large and globally distributed dataset (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig1">1</a>) for cloud semantic understanding based mainly on Sentinel 2 imagery. CloudSEN12 surpasses all previous efforts in size and variability (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab1">1</a>), offering 49,250 image patches (IPs) with different annotation types: (i) 10,000 IPs with high-quality pixel-level annotation, (ii) 10,000 IPs with scribble annotation, and (iii) 29,250 unlabeled IPs. The labeling phase was conducted by 14 domain experts using a supervised active learning system. We designed a rigorous four-step quality control protocol based on Zhu <i>et al</i>.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Zhu, X. X. et al. So2Sat LCZ42: A Benchmark Dataset for Global Local Climate Zones Classification. arXiv 14, 2–13 (2019)." href="/articles/s41597-022-01878-2#ref-CR34" id="ref-link-section-d75612378e1534">34</a></sup> to guarantee high quality in the manual annotation phase. Furthermore, CloudSEN12 ensures that for the same geographical location, users can obtain multiple IPs with different cloud coverage: cloud-free (0%), almost-clear (0–25%), low-cloudy (25–45%), mid-cloudy (45–65%), and cloudy (&gt;65%), which ensures scene variability in the temporal domain. Finally, to support multi-modal cloud removal<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Meraner, A., Ebel, P., Zhu, X. X. &amp; Schmitt, M. Cloud removal in Sentinel-2 imagery using a deep residual neural network and SAR-optical data fusion. ISPRS Journal of Photogrammetry and Remote Sensing 166, 333–346, &#xA;                  https://doi.org/10.1016/j.isprsjprs.2020.05.013&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR35" id="ref-link-section-d75612378e1539">35</a></sup> and data fusion<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Singh, P. &amp; Komodakis, N. Cloud-GAN: Cloud removal for sentinel-2 imagery using a cyclic consistent generative adversarial networks. International Geoscience and Remote Sensing Symposium (IGARSS) 2018-July, 1772–1775, &#xA;                  https://doi.org/10.1109/IGARSS.2018.8519033&#xA;                  &#xA;                 (2018)." href="/articles/s41597-022-01878-2#ref-CR36" id="ref-link-section-d75612378e1543">36</a></sup> approaches, each CloudSEN12 IP includes data from various remote sensing sources that have already shown their usefulness in cloud and cloud shadow masking, such as Sentinel-1 and elevation data. See Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab2">2</a> for a full list of assets available for each image patch.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="366"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>CloudSEN12 spatial coverage, purple-to-yellow color gradient represents the amount of manually annotated pixels per hexagon. The annotated pixels were collocated in an equal-area hexagonal discrete grid with a facet size of 140 km.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 List of assets available for each image patch.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41597-022-01878-2/tables/3" aria-label="Full size table 3"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Methods</h2><div class="c-article-section__content" id="Sec2-content"><p>This study collects and combines several public data sources that may potentially help us to annotate cloud and cloud shadows better. Based on this information, semantic classes (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab3">3</a>) are created using an active system that blends human photo interpretation and machine learning. Finally, a strict quality control protocol is carried out to ensure the highest quality on the manual labels and to establish human-level performance. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig2">2</a> depicts the whole workflow followed to create the dataset. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig2">2a</a> depicts all available data in each CloudSEN12 IP (see Method:Data preparation section). Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig2">2b</a> illustrates the manual IP selection strategy realized in each ROI (see Method:Image patches selection section). Finally, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig2">2c</a> highlights the human annotation strategy and cloud detection models offered in each IP (see Method:Annotation strategy and Method:Available cloud detection models sections).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Cloud semantic categories considered in CloudSEN12. Lower priority levels indicate greater relevance.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41597-022-01878-2/tables/4" aria-label="Full size table 4"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="701"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>A high-level summary of our workflow to generate IPs. (<b>a</b>) Satellite imagery datasets that comprises CloudSEN12 assets. (<b>b</b>) IP selection by the CDE group. (<b>c</b>) Generation of manual and automatic cloud masking. KappasMask and CD-FCNN have two distinct configurations.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec3">Data preparation</h3><p>CloudSEN12 comprises different free and open datasets provided by several public institutions and made accessible by the Google Earth Engine (GEE) platform<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Gorelick, N. et al. Google Earth Engine: Planetary-scale geospatial analysis for everyone. Remote Sensing of Environment 202, 18–27, &#xA;                  https://doi.org/10.1016/j.rse.2017.06.031&#xA;                  &#xA;                 (2017)." href="/articles/s41597-022-01878-2#ref-CR37" id="ref-link-section-d75612378e2824">37</a></sup>. These include Sentinel-2A/B (SEN2), Sentinel-1A/B (SEN1), Multi-Error-Removed Improved-Terrain (MERIT) DEM<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Yamazaki, D. et al. MERIT Hydro: A High-Resolution Global Hydrography Map Based on Latest Topography Dataset. Water Resources Research 55, 5053–5073, &#xA;                  https://doi.org/10.1029/2019WR024873&#xA;                  &#xA;                 (2019)." href="/articles/s41597-022-01878-2#ref-CR38" id="ref-link-section-d75612378e2828">38</a></sup>, Global Surface Water<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Pekel, J. F., Cottam, A., Gorelick, N. &amp; Belward, A. S. High-resolution mapping of global surface water and its long-term changes. Nature 540, 418–422, &#xA;                  https://doi.org/10.1038/nature20584&#xA;                  &#xA;                 (2016)." href="/articles/s41597-022-01878-2#ref-CR39" id="ref-link-section-d75612378e2832">39</a></sup> (GSW), and Global Land Cover maps<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Buchhorn, M. et al. Copernicus Global Land Service: Land Cover 100 m: Collection 3: epoch 2015: Globe (Version V3.0.1). Zenodo 1–14 (2020)." href="/articles/s41597-022-01878-2#ref-CR40" id="ref-link-section-d75612378e2836">40</a></sup> at 10 and 100 meters. The SEN1 and SEN2 multi-spectral image data correspond to the 2018–2020 period. We included all the bands from both SEN2 top-of-atmosphere (TOA) reflectance (Level-1C) and SEN2 surface reflectance (SR) values (Level-2A) derived from the Sen2Cor processor, which can be useful to analyze the impact of CD algorithms on atmospherically corrected derived products. See <i>S2L1C</i> and <i>S2L2A</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab2">2</a> for band description. On the other hand, SEN1 acquires data with a revisit cycle between 6–12 days according to four standard operational modes: Stripmap (SM), Extra Wide Swath (EW), Wave (WV), and Interferometric Wide Swath (IW). In CloudSEN12, we collect IW data with two polarization channels (VV and VH) from the high-resolution Level-1 Ground Range Detected (GRD) product. Furthermore, we saved the approximate angle between the incident SAR beam and the reference ellipsoid (see <i>S1</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab2">2</a>). Lastly, our dataset also includes previously proposed features for cloud semantic segmentation such as (1) Cloud Displacement Index<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Frantz, D., Haß, E., Uhl, A., Stoffels, J. &amp; Hill, J. Improvement of the Fmask algorithm for Sentinel-2 images: Separating clouds from bright surfaces based on parallax effects. Remote Sensing of Environment 215, 471–481, &#xA;                  https://doi.org/10.1016/j.rse.2018.04.046&#xA;                  &#xA;                 (2018)." href="/articles/s41597-022-01878-2#ref-CR41" id="ref-link-section-d75612378e2856">41</a></sup>, (2) the azimuth (0–360°) calculated using the solar azimuth and zenith angles<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Fernandez-Moran, R., Gómez-Chova, L., Alonso, L., Mateo-García, G. &amp; López-Puigdollers, D. Towards a novel approach for Sentinel-3 synergistic OLCI/SLSTR cloud and cloud shadow detection based on stereo cloud-top height estimation. ISPRS Journal of Photogrammetry and Remote Sensing 181, 238–253, &#xA;                  https://doi.org/10.1016/j.isprsjprs.2021.09.013&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR42" id="ref-link-section-d75612378e2860">42</a></sup> from SEN2 metadata, (3) elevation from MERIT dataset, (4) land cover maps from the Copernicus Global Land Service (CGLS) version 3, and the ESA WorldCover 10 m v100, and (5) water occurrence from the GSW dataset (see <i>extra/</i> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab2">2</a>). All the previous features constitute the raw CloudSEN12 imagery dataset (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig2">2a</a>). All the image scenes in raw CloudSEN12 were resampled to 10 meters using local SEN2 UTM coordinates.</p><h3 class="c-article__sub-heading" id="Sec4">Image patches selection</h3><p>We sampled 20,000 random regions of interest (ROIs) dispersed globally in order to retrieve raw CloudSEN12 data. Each ROI has a dimension of 5,090 × 5,090 meters. Besides, we carefully added 5,000 manually selected ROIs to guarantee high scene diversity on complicated surfaces such as snow and built-up areas. Afterwards, an ROI is retained in the dataset if all three of the following requirements are met: (1) SEN2 Level-1C IP does not include saturated or no-data pixel values, (2) the time difference between SEN1 and SEN2 acquisitions is not higher than 2.5 days, and (3) there are more than 15 SEN2 Level-1C image scenes for the given ROI after applying (2). The total number of ROIs decreased from 25,000 to 12,121 as a result of this filtering. Despite this reduction, CloudSEN12 still manages to reach a full global representation. However, a high number of ROIs does not necessarily imply a consistent distribution among cloud types and coverage. Unfortunately, image selection based on automatic cloud masking or cloud cover metadata tends to produce misleading results, especially under high-altitude areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Tiede, D., Sudmanns, M., Augustin, H. &amp; Baraldi, A. Investigating ESA Sentinel-2 products’ systematic cloud cover overestimation in very high altitude areas. Remote Sensing of Environment 252, 112163, &#xA;                  https://doi.org/10.1016/j.rse.2020.112163&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR43" id="ref-link-section-d75612378e2882">43</a></sup>, intricate backgrounds<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Rittger, K. et al. Canopy Adjustment and Improved Cloud Detection for Remotely Sensed Snow Cover Mapping. Water Resources Research 56, 1–20, &#xA;                  https://doi.org/10.1029/2019WR024914&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR44" id="ref-link-section-d75612378e2886">44</a></sup>, and mixed cloud types scenes. Hence, to guarantee unbiased distribution between clear, cloud and cloud shadow pixels, 14 cloud detection experts manually selected the IPs (hereafter referred to as CDE group, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig2">2b</a>). For each ROI, we pick five IPs with different cloud coverage: cloud-free (0%), almost-clear (0–25%), low-cloudy (25–65%), mid-cloudy (45–65%), and cloudy image (&gt;65%). Atypical clouds such as contrails, ice clouds, and haze/fog had a higher priority than common clouds (i.e., cumulus and stratus). After eliminating ROIs that did not count with at least one IP for each cloud coverage class, the total number of ROIs was reduced from 12,121 to 9,880, resulting in the final CloudSEN12 spatial coverage (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig1">1</a>).</p><h3 class="c-article__sub-heading" id="Sec5">Annotation strategy</h3><p>New trends in computer vision show that reformulating the standard supervised learning scheme can alleviate the huge demands of hand-crafted labeled data. For instance, semi-supervised learning can produce more detailed and uniform predictions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Castillo-Navarro, J., Saux, B. L., Boulch, A., Audebert, N. &amp; Lefèvre, S. Semi-Supervised Semantic Segmentation in Earth Observation: The MiniFrance Suite, Dataset Analysis and Multi-task Network Study. arxiv (2020)." href="/articles/s41597-022-01878-2#ref-CR45" id="ref-link-section-d75612378e2904">45</a></sup>, while weakly-supervised learning suggests a more cost-effective option to pixel-wise annotation in semantic segmentation. Users might utilize scribble labels to train a model for coarse-to-fine enrichment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Li, Y. et al. Accurate cloud detection in high-resolution remote sensing imagery by weakly supervised deep learning. Remote Sensing of Environment 250, 112045, &#xA;                  https://doi.org/10.1016/j.rse.2020.112045&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR46" id="ref-link-section-d75612378e2908">46</a></sup>. Aware of these manual labeling requirements, CloudSEN12 includes three types of labeling data: high-quality, scribble, and no-annotation. Consequently, each ROI is randomly assigned to a distinct annotation category (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig2">2c</a>) and labelled by the CDE group:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>2,000 ROIs with pixel level annotation, where the average annotation time is 150 minutes (high-quality subset, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig3">3a</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="798"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>The three primary types of hand-crafted labeling data available in CloudSEN12. The first row in high-quality (<b>a</b>), scribble (<b>b</b>), and no annotation (<b>c</b>) subgroups shows a SEN2 level 1 C RGB band combination.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div>
                  </li>
                  <li>
                    <p>2,000 ROIs with scribble level annotation, where the annotation time is 16 minutes (scribble subset, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig3">3b</a>).</p>
                  </li>
                  <li>
                    <p>5,880 ROIs with annotation only in the cloud-free (0%) image (no annotation subset, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig3">3c</a>).</p>
                  </li>
                </ul><h3 class="c-article__sub-heading" id="Sec6">Human calibration phase</h3><p>Human photo interpretation is not a faultless procedure. It might easily be skewed by an individual’s basis, overconfidence, tiredness, or ostrich-effect<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Valdez, C., Ziefle, M. &amp; Sedlmair, M. A Framework for Studying Biases in Visualization Research. VIS 2017: Dealing with Cognitive Biases in Visualisations (2017)." href="/articles/s41597-022-01878-2#ref-CR47" id="ref-link-section-d75612378e2980">47</a></sup> proclivity. Hence, to lessen this effect, the CDE group refined their criteria using a “calibration” dataset composed of 35 manually selected challenging IPs. In this stage, all the labelers can consult each other. As a result, they reached an agreement about the SEN2 band compositions to be used and how to deal with complicated scenarios such as cloud boundaries, thin cloud shadows, and high-reflectance background. A labeler is considered fully trained if its overall accuracy in the calibration dataset surpasses 90%. Then, a “validation” dataset formed of ten IPs is used to assess individual performance; labelers are not permitted to confer with one another during this step. If the labeler’s overall accuracy drops below 90%, it will return to the calibration phase (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig4">4</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/4" rel="nofollow"><picture><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="588"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Human calibration workflow diagram. The overall accuracy (OA) is calculated by comparing individual labeler results against expert group results.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec7">Labeling phase</h3><p>The Intelligence foR Image Segmentation (IRIS) active learning software<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Mrziglod, J. IRIS - Intelligence foR Image Segmentation (2019)." href="/articles/s41597-022-01878-2#ref-CR48" id="ref-link-section-d75612378e3012">48</a></sup> was used in the manual labeling annotation process (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41597-022-01878-2#MOESM1">S1</a>). IRIS allowed CDE members to train a model (learner) with a small set of labeled samples that is iteratively reinforced by acquiring new samples provided by a labeler (oracle). As a result, it dramatically decreases the time spent creating hand-crafted labels but maintains the labeler’s capacity to make final manual revisions if necessary. For high-quality labeling generation (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig5">5a</a>), IRIS starts training a gradient boosting decision tree (GBDT)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Friedman, J. H. Greedy function approximation: a gradient boosting machine. Annals of statistics 1189–1232 (2001)." href="/articles/s41597-022-01878-2#ref-CR49" id="ref-link-section-d75612378e3022">49</a></sup> with s2cloudless cloud probability values greater than 0.7 as thick cloud and less than 0.3 as clear. GBDT algorithm starts generating weak decision trees by dividing training data and gradually moving in the direction of lowering the loss function, then all the weak decision trees are combined into a single strong learner to generate a final prediction. IRIS use the LightGBM Python package. Readers are referred to Ke <i>et al</i>.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Ke, G. et al. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In Guyon, I. et al. (eds.) Advances in Neural Information Processing Systems, vol. 30 (2017)." href="/articles/s41597-022-01878-2#ref-CR50" id="ref-link-section-d75612378e3030">50</a></sup> for a detailed algorithm description. After obtaining GBDT predictions, the CDE group makes adjustments to the prior results and, if necessary, adds other cloud semantic classes such as cloud shadow and thin cloud. Using this new sample set, the GBDT model is re-trained. The two previous steps are repeated several times until the pixel-wise annotation passes the labeler’s visual inspection filter. The final high-quality annotation results are then obtained by applying extra manual fine-tuning. Since there are no quantitative criteria to distinguish between boundaries in semantic classes, the labelers always attempt to maximize the sensitivity score under ambiguous edges.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Fig. 5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="875"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>(<b>a</b>) High-quality labeling phase diagram. The model is set up using s2cloudless priors (blue). Annotations made by labelers with and without ML assistance are saved (green). (<b>b</b>) Scribble labeling phase diagram. The labelers starts by adding samples at the centroids (blue), and then into the borders; if the results pass a simple visual inspection, the annotation is send to inspection (see Method:Quality control phase section).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>On the other hand, for scribble labeling (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig5">5b</a>), the CDE group also used IRIS but without ML assistance. First, labelers spend one-minute adding annotations around centroids of the semantic classes. Usually, pixels adjacent to the centroids are more straightforward to classify automatically. Then, to produce balanced annotations, the CDE group added more samples at cloud and cloud shadow edges for three more minutes.</p><h3 class="c-article__sub-heading" id="Sec8">Quality control phase</h3><p>Despite the human calibration phase, errors are still common in hand-operated labels. Therefore, statistic and visual inspections were implemented before admitting a manual annotation in CloudSEN12 (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig6">6</a>). First, an automatic check is set only for high-quality labels. It proposes that the GBDT accuracy during training must be higher than 0.95. This simple threshold pushes the CDE group to set more samples and care more about labeling correctness. Later, two sequential visual inspection rounds are carried out for scribble and high-quality labels. The evaluators are two other CDE members than the one who labeled the IP. If a mistake is found, it is notified using GitHub Discussions (<a href="https://github.com/cloudsen12/models/discussions">https://github.com/cloudsen12/models/discussions</a>). Finally, we discern the most challenging IPs (difficulty level greater than 4, see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab4">4</a>) and consult all CDE members to reaffirm or change a semantic class. The deliberations were supported by using cloudApp (<a href="https://csaybar.users.earthengine.app/view/cloudapp">https://csaybar.users.earthengine.app/view/cloudapp</a>), which is a GEE web application that displays SEN2 image time series from any location on the earth (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41597-022-01878-2#MOESM1">S2</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Fig. 6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/6" rel="nofollow"><picture><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="376"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Flowchart overview of the entire QC process.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Metadata associated to each image patch.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41597-022-01878-2/tables/5" aria-label="Full size table 5"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Comparing the manual annotation before and after quality control can provide insight into the correctness of annotations made by humans. Based on this, CloudSEN12 set, for the first time, the human-level performance at 95.7% confidence when considering all semantic cloud classes (described in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab3">3</a>) and 98.3% if thin clouds are discarded. The clear and thick cloud classes presented the largest PA agreement with 99.1% and 96.6%, respectively (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig7">7</a>). The variance concerning the thick cloud class (3.4%) was produced by efforts to limit the formation of false positives around cloud borders in the first round of quality control. In contrast, thin cloud and cloud shadow classes present the largest disparities, with a PA of 78 and 91.8%, respectively. Despite using IRIS and CloudApp, which permits labelers to contrast both spectral and temporal SEN2 data, the detection of semi-transparent clouds remained unclear (21%). This was especially noticeable when all CDE members discussed the most complicated IPs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig6">6</a>); thin clouds were always the source of the most contention. Considering the assimilation of atmospheric reanalysis data and radiative transfer model outputs could help to reduce the cirrus detection uncertainty<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Qiu, S., Zhu, Z. &amp; Woodcock, C. E. Cirrus clouds that adversely affect Landsat 8 images: What are they and how to detect them? Remote Sensing of Environment 246, 111884, &#xA;                  https://doi.org/10.1016/j.rse.2020.111884&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR9" id="ref-link-section-d75612378e3571">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Mejia, F. A. et al. Coupling sky images with radiative transfer models: a new method to estimate cloud optical depth. Atmospheric Measurement Techniques 9, 4151–4165 (2016)." href="/articles/s41597-022-01878-2#ref-CR51" id="ref-link-section-d75612378e3574">51</a></sup>. Nonetheless, our manual labeling approach did not consider this additional data. Finally, cloud shadow disagreement is explained by a reinterpretation of the semantic classes after the first quality control round. At first, we assumed that only thick clouds could project shadows. However, this was ruled out as many thin low-altitude clouds project their shadows on the surface, significantly affecting surface reflectance values.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Fig. 7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig7_HTML.png?as=webp"><img aria-describedby="Fig7" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig7_HTML.png" alt="figure 7" loading="lazy" width="685" height="681"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Confusion matrix between high-quality manual labels cast by the CDE group before and after the quality control procedure. In the middle of each tile, we show the number of pixels and their ratios with respect to the total number of pixels. The true positive class agreement is expressed by the UA and PA at the right and bottom of the diagonal tiles.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec9">Available cloud detection models</h3><p>The large number of user requirements makes challenging to compare CD algorithms fairly<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Skakun, S. et al. Cloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2. Remote Sensing of Environment 274, 112990, &#xA;                  https://doi.org/10.1016/j.rse.2022.112990&#xA;                  &#xA;                 (2022)." href="/articles/s41597-022-01878-2#ref-CR24" id="ref-link-section-d75612378e3603">24</a></sup>. In crop detection, for instance, examining the performance of CD models during specific seasons rather than on an interannual scale may be more meaningful. Another example is that some data users may want to compare CD model performance geographically across different biomes or land-cover classes. In EO research that uses deep learning, it has become rather common to benchmark models as classic computer vision algorithms, generating global metric values for each validation dataset. However, this convenient approach is more likely to result in biased conclusions, especially using poorly distributed datasets. We argue that an appropriate model in EO must be capable of obtaining adequate global metrics while being consistent in space across multiple timescales, i.e., at the local domain. Furthermore, in cloud detection, the observed patterns must be aligned with our physical understanding of the phenomena. All of the above is hard to express in a single global metric value. Therefore, in order to cover all the possible EO benchmarking user requirements, we added to each IP the results of eight of the most popular CD algorithms (see <i>labels/</i>in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab2">2</a>). This simple step provides CloudSEN12 users more flexibility to choose a better comparison strategy tailored to their requirements. Next, we detail the CD algorithms available for each IP in CloudSEN12:</p><ul class="u-list-style-bullet">
                  <li>
                    <p>Fmask4: Function of Mask cloud detection algorithm for Landsat and Sentinel-2<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Qiu, S., Zhu, Z. &amp; He, B. Remote Sensing of Environment Fmask 4. 0: Improved cloud and cloud shadow detection in Landsats 4–8 and Sentinel-2 imagery. Remote Sensing of Environment 231, 111205, &#xA;                  https://doi.org/10.1016/j.rse.2019.05.024&#xA;                  &#xA;                 (2019)." href="/articles/s41597-022-01878-2#ref-CR11" id="ref-link-section-d75612378e3619">11</a></sup>. We use the authors’ MATLAB implementation code via Linux Docker containers (<a href="https://github.com/cloudsen12/models">https://github.com/cloudsen12/models</a>). We set the dilatation parameter for cloud, cloud shadow, and snow to 3, 3, and 0 pixels, respectively. The erosion radius (dilation) is set to 0 (90) meters, while the cloud probability threshold is fixed to 20%.</p>
                  </li>
                  <li>
                    <p>Sen2Cor: Software that performs atmospheric, terrain, and cirrus correction to SEN2 Level-1C input data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Louis, J. et al. Sentinel-2 SEN2COR: L2A processor for users. European Space Agency, (Special Publication) ESA SP SP-740, 9–13 (2016)." href="/articles/s41597-022-01878-2#ref-CR12" id="ref-link-section-d75612378e3636">12</a></sup>. We store the Scene Classification (SC), which provides a semantic pixel-level classification map. The SC maps are obtained from the “COPERNICUS/S2_SR” GEE dataset.</p>
                  </li>
                  <li>
                    <p>s2cloudless: Single-scene CD algorithm created by Sentinel-Hub using a LightGBM decision tree model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Ke, G. et al. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In Guyon, I. et al. (eds.) Advances in Neural Information Processing Systems, vol. 30 (2017)." href="/articles/s41597-022-01878-2#ref-CR50" id="ref-link-section-d75612378e3646">50</a></sup>. The cloud probability values are collected without applying neither a threshold nor dilation. This resource is available in the “COPERNICUS/S2_CLOUD_PROBABILITY” GEE dataset.</p>
                  </li>
                  <li>
                    <p>CD-FCNN: U-Net with two different SEN2 band combinations:<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="López-Puigdollers, D., Mateo-García, G. &amp; Gómez-Chova, L. Benchmarking deep learning models for cloud detection in landsat-8 and sentinel-2 images. Remote Sensing 13, 1–20, &#xA;                  https://doi.org/10.3390/rs13050992&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR23" id="ref-link-section-d75612378e3656">23</a></sup> RGBI (B2, B3, B4, and B8) and RGBISWIR (B2, B3, B4, B8, B11, and B12) trained on the Landsat Biome-8 dataset (transfer learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Mateo-García, G., Laparra, V., López-Puigdollers, D. &amp; Gómez-Chova, L. Transferring deep learning models for cloud detection between Landsat-8 and Proba-V. ISPRS Journal of Photogrammetry and Remote Sensing 160, 1–17, &#xA;                  https://doi.org/10.1016/j.isprsjprs.2019.11.024&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR52" id="ref-link-section-d75612378e3660">52</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Mateo-García, G., Laparra, V., López-Puigdollers, D. &amp; Gómez-Chova, L. Cross-Sensor Adversarial Domain Adaptation of Landsat-8 and Proba-V Images for Cloud Detection. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 14, 747–761, &#xA;                  https://doi.org/10.1109/JSTARS.2020.3031741&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR53" id="ref-link-section-d75612378e3663">53</a></sup> from Landsat 8 to Sentinel-2).</p>
                  </li>
                  <li>
                    <p>KappaMask: U-Net with two distinct settings:<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Domnich, M. et al. KappaMask: Ai-based cloudmask processor for sentinel-2. Remote Sensing 13, &#xA;                  https://doi.org/10.3390/rs13204100&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR54" id="ref-link-section-d75612378e3673">54</a></sup> all Sentinel-2 L1C bands and all Sentinel-2 L2A bands except the Red Edge 3 band. It was trained using both Sentinel-2 KappaZeta Cloud and Cloud Shadow Masks and the Sentinel-2 Cloud Mask Catalogue (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab1">1</a>).</p>
                  </li>
                  <li>
                    <p>QA60: Cloud mask embedded in the quality assurance band of SEN2 Level-1C products.</p>
                  </li>
                </ul><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab5">5</a> shows the cloud semantic categories for the different CD techniques available in CloudSEN12. It should be noted that only four CD algorithms provide the cloud shadow category.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Output correspondence for the available CD algorithms.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41597-022-01878-2/tables/6" aria-label="Full size table 6"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec10">Preparing CloudSEN12 for machine learning</h3><p>Splitting our densely annotated dataset into train and test sets is critical to ensure that ML practitioners always use the same samples when providing results. Since cloud formation tends to fluctuate smoothly throughout space, a simple random split is suspicious to violate the assumption of test independence, especially under highly clustered labeled areas, such as the green and yellow regions shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig1">1</a>. Therefore, we carry out a spatially stratified block split strategy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Valavi, R., Elith, J., Lahoz-Monfort, J. J. &amp; Guillera-Arroita, G. blockCV: An r package for generating spatially or environmentally separated folds for k-fold cross-validation of species distribution models. Methods in Ecology and Evolution 10, 225–232, &#xA;                  https://doi.org/10.1111/2041-210X.13107&#xA;                  &#xA;                 (2019)." href="/articles/s41597-022-01878-2#ref-CR55" id="ref-link-section-d75612378e3987">55</a></sup>, based on Roberts <i>et al</i>.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Roberts, D. R. et al. Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure. Ecography 40, 913–929, &#xA;                  https://doi.org/10.1111/ecog.02881&#xA;                  &#xA;                 (2017)." href="/articles/s41597-022-01878-2#ref-CR56" id="ref-link-section-d75612378e3994">56</a></sup>, to limit the risk of overfitting induced by spatial autocorrelation. First, we divided the Earth’s surface into regular hexagons of 50,000 <i>km</i><sup>2</sup>. Then, the initial hexagons are filtered, retaining only those intersecting with the high-quality subset. Finally, using the difficulty IP property (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab3">3</a>), we randomly stratified the remained hexagon blocks using 90% (1827 ROIs) and 10% (173 ROIs) for training and testing, respectively (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig8">8</a>). Notice that on each ROI, we have five IPs hence the total amount of training and testing data is five times these numbers. The no annotation and scribble subsets might be used as additional inputs for the training phase.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8" data-title="Fig. 8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig8_HTML.png?as=webp"><img aria-describedby="Fig8" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig8_HTML.png" alt="figure 8" loading="lazy" width="685" height="349"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Location of the training (grey) and testing (black) regions. The IPs were collocated in a equal-area hexagonal discrete grid with a facet size of 140 km.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/8" data-track-dest="link:Figure8 Full size image" aria-label="Full size image figure 8" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="Data Records"><div class="c-article-section" id="Sec11-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">Data Records</h2><div class="c-article-section__content" id="Sec11-content"><p>The dataset is available online via Science Data Bank<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Luis, C. et al. CloudSEN12 - a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2. Science Data Bank &#xA;                  https://doi.org/10.57760/sciencedb.06669&#xA;                  &#xA;                 (2022)." href="/articles/s41597-022-01878-2#ref-CR57" id="ref-link-section-d75612378e4035">57</a></sup>. We defined an IP as the primary atomic unit, representing a single spatio-temporal component. Each IP has 49 assets (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab2">2</a>) and 31 properties (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab4">4</a>). All the assets are delivered in the form of LZW-compressed COG (Cloud Optimized GeoTIFF) files. COG is a standard imagery format for web-optimized access to raster data. It has a specific internal pixel structure that allows clients to request just specified areas of a large image by submitting HTTP range requests<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Iosifescu Enescu, I. et al. Cloud optimized raster encoding (core): A web-native streamable format for large environmental time series. Geomatics 1, 369–382 (2021)." href="/articles/s41597-022-01878-2#ref-CR58" id="ref-link-section-d75612378e4045">58</a></sup>. The IP properties are shared using the SpatioTemporal Asset Catalog (STAC) specification. STAC provides a straightforward architecture for reading metadata and assets in JSON format, providing users with a sophisticated browsing experience seamlessly integrating with modern scripting languages and front-end web technologies.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig10">10</a> shows the CloudSEN12 dataset organization, which follows a four-level directory structure. The top level includes the metadata file in CSV format (content of Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab4">4</a>) and three folders: high, scribble, and no-label. These folders correspond to the annotation categories: high-quality (2000 ROIs), scribble (2000 ROIs), and no annotation (5880 ROIs). The second-level folders correspond to each specific geographic location (ROI). The folder name is the ROI ID (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig10">10b</a>). Since an ROI consists of five IPs with different cloud coverage, each ROI folder contains five folders whose names match the GEE Sentinel-2 product ID of the specific IP (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig10">10c</a>). Finally, each IP folder stores the assets detailed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab2">2</a> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig10">10d</a>).</p></div></div></section><section data-title="Technical Validation"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Technical Validation</h2><div class="c-article-section__content" id="Sec12-content"><h3 class="c-article__sub-heading" id="Sec13">Neural network architecture</h3><p>In order to demonstrate cloudSEN12’s effectiveness in developing DD models, we trained a U-Net<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Ronneberger, O., Fischer, P. &amp; Brox, T. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention, 234–241 (Springer, 2015)." href="/articles/s41597-022-01878-2#ref-CR59" id="ref-link-section-d75612378e4083">59</a></sup> network with a MobileNetV2<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Sandler, M., Howard, A., Zhu, M., Zhmoginov, A. &amp; Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 4510–4520 (2018)." href="/articles/s41597-022-01878-2#ref-CR60" id="ref-link-section-d75612378e4087">60</a></sup> backbone (UNetMobV2) using only the high-quality pixel-level annotation set. U-Net models often have considerable memory requirements since the encoder and decoder components include skip connections of large tensors. However, the MobileNetV2 encoder significantly decreases memory utilization due to the use of depthwise separable convolutions and inverted residuals. The entire memory requirements of our model, considering a batch with a single image (1 × 13 × 512 × 512), the forward/backward pass, and model parameters, is less than 1 GB using the PyTorch deep learning library<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Paszke, A. et al. Pytorch: An imperative style, high-performance deep learning library. In Wallach, H. et al. (eds.) Advances in Neural Information Processing Systems 32, 8024–8035 (Curran Associates, Inc., 2019)." href="/articles/s41597-022-01878-2#ref-CR61" id="ref-link-section-d75612378e4091">61</a></sup>. The implementation of the proposed model can be found at <a href="https://github.com/cloudsen12/models">https://github.com/cloudsen12/models</a>.</p><p>The high-quality set is split into training, validation, and test sets. First, we obtain the test and no-test set using the previous geographical blocks. Then, the no-test set is randomly divided into training and validation sets according to the ratio of 90/10%. The U-Net network is trained considering all the SEN2 L1C bands with a batch size of 32, Adam optimizer with a learning rate of 10<sup>−3</sup>, and the standard cross-entropy as loss function. During the training phase, the learning rate is lowered by a factor of 0.10 if the cross-entropy measured in the validation set does not improve in four epochs. Lastly, if the model does not improve after ten epochs, the model with the lowest cross-entropy value in the validation set is chosen.</p><h3 class="c-article__sub-heading" id="Sec14">Benckmarking strategy</h3><p>CloudSEN12’s suitability for benchmarking cloud and cloud shadow is discussed in this section. In order to maintain fairness, we only consider the 975 IPs available in the test set. We assessed the similarity between the semantic categories (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab3">3</a>) from CD models (automatic) and manual annotations through three experiments. First, we created the “cloud” and “non-cloud” superclasses (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab3">3</a>) that aggregate thick and thin cloud and clear and cloud shadows classes, respectively. In the second experiment, cloud shadows are validated by considering four algorithms: UNetMobV2, KappaMask, Fmask, and Sen2Cor, as not all algorithms are capable of detecting cloud shadows (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab5">5</a>). Finally, in the third experiment, “valid” and “invalid” superclasses (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab3">3</a>) are also analyzed just for algorithms with cloud shadow detection. In all the experiments, human-level performance is included by comparing manual annotations before and after the quality control procedure (see Method: Quality control phase section). We report producer’s accuracy (PA), user’s accuracy (UA), and balanced overall accuracy (BOA) as metrics to assess the disparities between predicted and expected pixels:</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$${\rm{PA}}=\frac{TP}{TP+FN}\quad \quad {\rm{UA}}=\frac{TP}{TP+FP}\quad \quad {\rm{BOA}}=0.5\left(PA+\frac{TN}{TN+FP}\right)$$</span></div><div class="c-article-equation__number">
                    (1)
                </div></div><p>Where <i>TP</i>, <i>TN</i>, <i>FP</i>, and <i>FN</i> denote true positive, true negative, false positive, and false negative. High PA values show that cloud pixels have been effectively masked out (clear-sky conservative approaches). In contrast, high UA values indicate that the algorithm is cautious in excluding non-cloud pixels (conservative cloud approaches). High BOA values are related to a good balance of false positives and false negatives. We generate a unique set of PA, UA, and BOA values for each test IP. Since the PA and UA values are always zero in cloudless IPs, they were replaced by NaN to prevent negative bias in the results. Then to report the summarized PA and UA metrics (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6</a>), we consider the following three scenarios: (i) low values group (<i>PA</i><sub><i>low</i></sub>% and <i>UA</i><sub><i>low</i></sub>%), which represents the percentage of IPs with PA/UA values lower than 0.1; (ii) middle values group (<i>PA</i><sub><i>middle</i></sub>% and <i>UA</i><sub><i>middle</i></sub>%) which represents the percentage of IPs between 0.1 and 0.9; (iii) high values group (<i>PA</i><sub><i>high</i></sub>% and <i>UA</i><sub><i>high</i></sub>%) which represents the percentage of total IPs higher than 0.9. In contrast to UA and PA, we calculate the median of all IPs for BOA estimates.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-7"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Metrics of the three different experiments for all the annotation algorithms.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41597-022-01878-2/tables/7" aria-label="Full size table 7"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec15">Cloud vs non-cloud</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig9">9</a> and Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6a</a> show BOA, PA, and UA density error curves and summary statistics for the first experiment. Excluding UNetMobV2 results, BOA and PA values exhibited a well-defined binomial error distribution with peak modes of different intensities. We found that the mode of the secondary peak is close to 0.5 and 0 for BOA and PA, respectively. Considering the three algorithms with the highest BOA, we found that this secondary distribution contains at least 3.86% of the total IPs (see PA<sub><i>low</i></sub> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6a</a>) and 38.83% of the IPs fall between the transition of these two distributions (see PA<sub><i>middle</i></sub> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6a</a>). A simple visual examination reveals that the omission of small and thin clouds is the primary cause of PA<sub><i>low</i></sub> values, whereas PA<sub><i>middle</i></sub> is mainly attributable to cloud borders misinterpretation. Low-thickness clouds, such as cirrus and haze, tend to produce more omission errors independent of the cloud detection algorithm. In KD algorithms, this can be explained by the simplicity of semitransparent cloud modules, which are just a conservative threshold in the cirrus band (B10). Additionally, thin clouds are often overlooked or unfairly reported in most CD datasets<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="European Space Agency. CEOS-WGCV ACIX II CMIX Atmospheric Correction Inter-comparison Exercise Cloud Masking Inter-comparison Exercise 2nd workshop (2019). Online; accessed 14 October 2021." href="/articles/s41597-022-01878-2#ref-CR62" id="ref-link-section-d75612378e5549">62</a></sup>. In the primary distribution, the peak’s mode is close to 0.90 and 0.95 for BOA and PA values, holding 57.31% of the IPs (see PA<sub><i>high</i></sub> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6a</a>). These results suggest that more than half of the IPs in CloudSEN12 are easily recognizable by automatic cloud masking algorithms.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9" data-title="Fig. 9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig9_HTML.png?as=webp"><img aria-describedby="Fig9" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig9_HTML.png" alt="figure 9" loading="lazy" width="685" height="640"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>BOA, PA, and UA comparison for the CloudSEN12 dataset. The upper figure depicts BOA density estimations for all CloudSEN12 IPs high-quality. The colors reflect the tail probability estimated by 0.5-<i>abs</i>(0.5-<i>ecdf</i>), where <i>ecdf</i> is the empirical cumulative distribution function. The vertical black lines drawn represent the first, second, and third quartiles, respectively. The heatlines in the lower figure shows the PA and UA value distribution. The red stars shows the median and the gray lines the 25th and 75th percentiles.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/9" data-track-dest="link:Figure9 Full size image" aria-label="Full size image figure 9" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10" data-title="Fig. 10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig10_HTML.png?as=webp"><img aria-describedby="Fig10" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_Fig10_HTML.png" alt="figure 10" loading="lazy" width="685" height="416"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Folder structure of the CloudSEN12 dataset. level zero: type of manual annotation, level one: geographic location (ROI), level 2: IP (for each ROI there are 5 IPs with different amount of cloud coverage), level 3: asset level where files in COG formats are stored.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41597-022-01878-2/figures/10" data-track-dest="link:Figure10 Full size image" aria-label="Full size image figure 10" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41597-022-01878-2#Fig9">9</a> demonstrates furthermore that not all algorithms exhibit the same behavior. Based on the PA and UA metrics, we may differentiate between three types of algorithms: quite balanced (UNetMobV2, Fmask, and KappaMask L1C), cloud conservative (CD-FCNN, QA60, s2cloudless, and Sen2Cor), and non-cloud conservative (KappaMask L2A). The first group reports similar values between PA<sub><i>high</i></sub> and UA<sub><i>high</i></sub> percentages. In contrast, the second group exhibits high UA values at the expense of worsening PA. As observed in the PA heatline plot, these algorithms show a pronounced bimodal distribution and a wide interquartile range, with more than half of the IPs exhibiting PA values below 0.5. Considering the high temporal resolution of SEN2 imagery, it seems unsuitable to use cloud-conservative algorithms for CD, except maybe for extremely cloudy regions where each clear pixel is critical<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="European Space Agency. CEOS-WGCV ACIX II CMIX Atmospheric Correction Inter-comparison Exercise Cloud Masking Inter-comparison Exercise 2nd workshop (2019). Online; accessed 14 October 2021." href="/articles/s41597-022-01878-2#ref-CR62" id="ref-link-section-d75612378e5619">62</a></sup>. On the other hand, in non-cloud conservative algorithms, over half of all IPs have PA values greater than 0.9 (see column PA<sub><i>high</i></sub> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6a</a>), but as a result, the UA<sub><i>high</i></sub> metric decrease significantly.</p><p>Based on BOA estimates (see column BOA in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6a</a>), we may conclude that QA60 is the most unreliable algorithm, failing to distinguish both cloud and non-cloud pixels. Whereas UNetMobV2 is clearly the best at detecting clouds, even semitransparent and small clouds, that other algorithms usually overlook. Although the UNetMobV2 and KappaMask are based on a similar network, we observe that KappaMask (in particular version 2A) tends to overestimate clouds under specific land cover types, such as mountains, open/enclosed water bodies, and coastal environments. Considering that the L1C and L2A versions of KappaMask are fine-tuned on a relatively small dataset from Northern Europe, it is expected that fine-tuning in CloudSEN12 should lead to better results on a global evaluation. Finally, we can conclude that UNetMobV2, Fmask, and KappaMask level 1C provide the most stable solution for cloud masking, with inaccuracies evenly distributed across different cloud types and land covers.</p><h3 class="c-article__sub-heading" id="Sec16">Cloud shadows</h3><p>Quantitative evaluations of cloud shadow detection on CloudSEN12 are presented in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6b</a>. The percentage of IPs with PA values &lt; 0.1 (PA<sub><i>low</i></sub>) ranges from 64.50% for Sen2Cor to 8.88% for UNetMobV2, indicating that a large number of cloud shadow pixels are omitted in all the algorithms. In contrast to the cloud/no-cloud experiment, the vast majority of IPs belong to the PA<sub><i>middle</i></sub> and UA<sub><i>middle</i></sub> groups, except for Sen2Cor, which belongs to the PA<sub><i>low</i></sub> group. The PA<sub><i>high</i></sub> percentage value was unexpectedly low, suggesting that the ground truth and predicted values rarely collocate perfectly over the same area. Comparing the results of the first and second experiments reveals that correctly detecting thick and thin clouds is not guaranteed for achieving a high PA score in cloud shadows. Besides, our results suggest that DL-based approaches (KappaMask and UNetMobV2) outperform KD algorithms (Sen2Cor and Fmask). This seems reasonable, given that KappaMask and UNetMobV2 are built on a multi-resolution model. Hence, it is probable that the model learns to identify the spatial coherence between clouds and cloud shadows classes.</p><h3 class="c-article__sub-heading" id="Sec17">Valid vs invalid</h3><p>In this section, we examine the combined detection of cloud and cloud shadows of five automatic CD algorithms (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41597-022-01878-2#Tab6">6c</a>). The reported metrics show a slight decrease in the PA<sub><i>high</i></sub> values of Fmask, Sen2Cor, and KappaMask L1C models compared to the first experiment. Consequently, the KappaMask L2A model significantly lowers its PA<sub><i>high</i></sub> value from 65.25 to 57.66%, indicating that this model tends to confuse cloud shadow with clear pixels. In contrast, UNetMobV2 slightly increased its reported PA<sub><i>high</i></sub> value from 68.60 to 70.66%. This is explained by the fact that UNetMobV2 tends to err thin cloud pixels with cloud shadows and vice versa, and since both belong to the same superclass in this experiment, these inconsistencies are considered true positives. Finally, further studies are required to identify the circumstances in which CD algorithms depart most from human-level performance to deliver superior automatic CD algorithms.</p><h3 class="c-article__sub-heading" id="Sec18">Discussion of experimental results</h3><p>In the three experiments, UNetMobV2 delivers the best balance between false negative and false positive errors. These outcomes are expected due to the more extensive and diverse image patches utilized during training. However, because deep learning models are prone to handle target shift poorly, the use of other datasets (e.g., PixBox<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Paperin, M., Wevers, J., Stelzer, K. &amp; Brockmann, C. PixBox Sentinel-2 pixel collection for CMIX. Zenodo &#xA;                  https://doi.org/10.5281/zenodo.5036991&#xA;                  &#xA;                 (2021)." href="/articles/s41597-022-01878-2#ref-CR63" id="ref-link-section-d75612378e5705">63</a></sup> or Hollstein<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Hollstein, A., Segl, K., Guanter, L., Brell, M. &amp; Enesco, M. Ready-to-use methods for the detection of clouds, cirrus, snow, shadow, water and clear sky pixels in Sentinel-2 MSI images. Remote Sensing 8, 1–18, &#xA;                  https://doi.org/10.3390/rs8080666&#xA;                  &#xA;                 (2016)." href="/articles/s41597-022-01878-2#ref-CR28" id="ref-link-section-d75612378e5709">28</a></sup>) might aid in corroborating these findings. Furthermore, the Sen2Cor results are estimated without considering changes between different versions (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41597-022-01878-2#MOESM1">S3</a>). Therefore, the values reported here could vary from those obtained using only the latest version (version 2.10, accessed on 9 July 2022). In addition, it is important to note that, in contrast to FMask and Sen2Cor, KappaMask and UNetMobV2 results are produced without image boundary data. Therefore, expanding the IP size might improve the reported metrics, particularly for the cloud shadows experiment.</p></div></div></section><section data-title="Usage Notes"><div class="c-article-section" id="Sec19-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec19">Usage Notes</h2><div class="c-article-section__content" id="Sec19-content"><p>This paper introduces CloudSEN12, a new large dataset for cloud semantic understanding, comprising 49,400 image patches distributed across all continents except Antarctica. The dataset has a total size of up to 1 TB. Nevertheless, we assume most user experiments need only a fraction of CloudSEN12. Therefore, to simplify its use, we developed a Python package called <i>cloudsen12</i> (<a href="https://github.com/cloudsen12/cloudsen12">https://github.com/cloudsen12/cloudsen12</a>). This Python package aims to help machine learning and remote sensing practitioners to:</p><ul class="u-list-style-bullet">
                <li>
                  <p>Query and download cloudSEN12 using a user-friendly interface.</p>
                </li>
                <li>
                  <p>Predict cloud semantics using the trained UNetMobV2 model.</p>
                </li>
              </ul><p>The CloudSEN12 website <a href="https://cloudsen12.github.io/">https://cloudsen12.github.io/</a> includes tutorials for querying and downloading the dataset using the <i>cloudsen12</i> package. Besides, there are examples of how to train DL models using PyTorch. Finally, although CloudSEN12 was initially designed for cloud semantic segmentation, it can be easily adapted to tackle other remote sensing problems like SAR-sharpening<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Schmitt, A. &amp; Wendleder, A. SAR-sharpening in the Kennaugh framework applied to the fusion of multi-modal SAR and optical images. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences 4, 133–140, &#xA;                  https://doi.org/10.5194/isprs-annals-IV-1-133-2018&#xA;                  &#xA;                 (2018)." href="/articles/s41597-022-01878-2#ref-CR64" id="ref-link-section-d75612378e5762">64</a></sup>, colorizing SAR images<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Schmitt, M., Hughes, L. H., Körner, M. &amp; Zhu, X. X. Colorizing sentinel-1 SAR images using a variational autoencoder conditioned on Sentinel-2 imagery. International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives 42, 1045–1051, &#xA;                  https://doi.org/10.5194/isprs-archives-XLII-2-1045-2018&#xA;                  &#xA;                 (2018)." href="/articles/s41597-022-01878-2#ref-CR65" id="ref-link-section-d75612378e5766">65</a></sup>, and SAR-optical image matching<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Hughes, L. H., Schmitt, M., Mou, L., Wang, Y. &amp; Zhu, X. X. Identifying Corresponding Patches in SAR and Optical Images with a Pseudo-Siamese CNN. IEEE Geoscience and Remote Sensing Letters 15, 784–788, &#xA;                  https://doi.org/10.1109/LGRS.2018.2799232&#xA;                  &#xA;                 (2018)." href="/articles/s41597-022-01878-2#ref-CR66" id="ref-link-section-d75612378e5770">66</a></sup>. Furthermore, by combining CloudSEN12 with ESA WorldCover 10 m v100, users may train land cover models to be aware of cloud contamination.</p></div></div></section>
                </div>
            

            <div>
                <section data-title="Code availability"><div class="c-article-section" id="code-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="code-availability">Code availability</h2><div class="c-article-section__content" id="code-availability-content">
              
              <p>The code to (1) create the raw CloudSEN12 imagery dataset, (2) download assets associated with each ROI, (3) create the manual annotations, (4) build and deploy cloudApp, (5) generate automatic cloud masking, (6) reproduce all the figures, (7) replicate the technical validation, (8) modify <i>cloudsen12</i> Python package, and (9) train DL models are available in our GitHub organization <a href="https://github.com/cloudsen12/">https://github.com/cloudsen12/</a>.</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Mahecha, M. D. <i>et al</i>. Earth system data cubes unravel global multivariate dynamics. <i>Earth System Dynamics</i> <b>11</b>, 201–234, <a href="https://doi.org/10.5194/esd-11-201-2020" data-track="click" data-track-action="external reference" data-track-label="10.5194/esd-11-201-2020">https://doi.org/10.5194/esd-11-201-2020</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.5194/esd-11-201-2020" data-track-action="article reference" href="https://doi.org/10.5194%2Fesd-11-201-2020" aria-label="Article reference 1" data-doi="10.5194/esd-11-201-2020">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020ESD....11..201M" aria-label="ADS reference 1">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Earth%20system%20data%20cubes%20unravel%20global%20multivariate%20dynamics&amp;journal=Earth%20System%20Dynamics&amp;doi=10.5194%2Fesd-11-201-2020&amp;volume=11&amp;pages=201-234&amp;publication_year=2020&amp;author=Mahecha%2CMD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Giuliani, G., Camara, G., Killough, B. &amp; Minchin, S. Earth observation open science: enhancing reproducible science using data cubes. <i>Data</i> <b>4</b>, 4–9, <a href="https://doi.org/10.3390/data4040147" data-track="click" data-track-action="external reference" data-track-label="10.3390/data4040147">https://doi.org/10.3390/data4040147</a> (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/data4040147" data-track-action="article reference" href="https://doi.org/10.3390%2Fdata4040147" aria-label="Article reference 2" data-doi="10.3390/data4040147">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Earth%20observation%20open%20science%3A%20enhancing%20reproducible%20science%20using%20data%20cubes&amp;journal=Data&amp;doi=10.3390%2Fdata4040147&amp;volume=4&amp;pages=4-9&amp;publication_year=2019&amp;author=Giuliani%2CG&amp;author=Camara%2CG&amp;author=Killough%2CB&amp;author=Minchin%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Gomes, V. C., Queiroz, G. R. &amp; Ferreira, K. R. An overview of platforms for big earth observation data management and analysis. <i>Remote Sensing</i> <b>12</b>, 1–25, <a href="https://doi.org/10.3390/RS12081253" data-track="click" data-track-action="external reference" data-track-label="10.3390/RS12081253">https://doi.org/10.3390/RS12081253</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/RS12081253" data-track-action="article reference" href="https://doi.org/10.3390%2FRS12081253" aria-label="Article reference 3" data-doi="10.3390/RS12081253">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20overview%20of%20platforms%20for%20big%20earth%20observation%20data%20management%20and%20analysis&amp;journal=Remote%20Sensing&amp;doi=10.3390%2FRS12081253&amp;volume=12&amp;pages=1-25&amp;publication_year=2020&amp;author=Gomes%2CVC&amp;author=Queiroz%2CGR&amp;author=Ferreira%2CKR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Wilson, A. M. &amp; Jetz, W. Remotely Sensed High-Resolution Global Cloud Dynamics for Predicting Ecosystem and Biodiversity Distributions. <i>PLoS Biology</i> <b>14</b>, 1–20, <a href="https://doi.org/10.1371/journal.pbio.1002415" data-track="click" data-track-action="external reference" data-track-label="10.1371/journal.pbio.1002415">https://doi.org/10.1371/journal.pbio.1002415</a> (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pbio.1002415" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pbio.1002415" aria-label="Article reference 4" data-doi="10.1371/journal.pbio.1002415">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28XhsFeisr3P" aria-label="CAS reference 4">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Remotely%20Sensed%20High-Resolution%20Global%20Cloud%20Dynamics%20for%20Predicting%20Ecosystem%20and%20Biodiversity%20Distributions&amp;journal=PLoS%20Biology&amp;doi=10.1371%2Fjournal.pbio.1002415&amp;volume=14&amp;pages=1-20&amp;publication_year=2016&amp;author=Wilson%2CAM&amp;author=Jetz%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Ebel, P., Meraner, A., Schmitt, M. &amp; Zhu, X. X. Multi-sensor data fusion for cloud removal in global and all-season sentinel-2 imagery. <i>arXiv</i> 1–13, <a href="https://doi.org/10.1109/tgrs.2020.3024744" data-track="click" data-track-action="external reference" data-track-label="10.1109/tgrs.2020.3024744">https://doi.org/10.1109/tgrs.2020.3024744</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Lynch, D. K., Sassen, K., Starr, D. O. &amp; Stephens, G. <i>Cirrus</i> (Oxford University Press, 2002).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Chen, B., Huang, B., Chen, L. &amp; Xu, B. Spatially and Temporally Weighted Regression: A Novel Method to Produce Continuous Cloud-Free Landsat Imagery. <i>IEEE Transactions on Geoscience and Remote Sensing</i> <b>55</b>, 27–37, <a href="https://doi.org/10.1109/TGRS.2016.2580576" data-track="click" data-track-action="external reference" data-track-label="10.1109/TGRS.2016.2580576">https://doi.org/10.1109/TGRS.2016.2580576</a> (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TGRS.2016.2580576" data-track-action="article reference" href="https://doi.org/10.1109%2FTGRS.2016.2580576" aria-label="Article reference 7" data-doi="10.1109/TGRS.2016.2580576">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2017ITGRS..55...27C" aria-label="ADS reference 7">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatially%20and%20Temporally%20Weighted%20Regression%3A%20A%20Novel%20Method%20to%20Produce%20Continuous%20Cloud-Free%20Landsat%20Imagery&amp;journal=IEEE%20Transactions%20on%20Geoscience%20and%20Remote%20Sensing&amp;doi=10.1109%2FTGRS.2016.2580576&amp;volume=55&amp;pages=27-37&amp;publication_year=2017&amp;author=Chen%2CB&amp;author=Huang%2CB&amp;author=Chen%2CL&amp;author=Xu%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Mateo-Garcia, G. <i>et al</i>. Towards global flood mapping onboard low cost satellites with machine learning. <i>Scientific Reports</i> <b>11</b>, 7249, <a href="https://doi.org/10.1038/s41598-021-86650-z" data-track="click" data-track-action="external reference" data-track-label="10.1038/s41598-021-86650-z">https://doi.org/10.1038/s41598-021-86650-z</a> (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41598-021-86650-z" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41598-021-86650-z" aria-label="Article reference 8" data-doi="10.1038/s41598-021-86650-z">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3MXotFWqsLw%3D" aria-label="CAS reference 8">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20global%20flood%20mapping%20onboard%20low%20cost%20satellites%20with%20machine%20learning&amp;journal=Scientific%20Reports&amp;doi=10.1038%2Fs41598-021-86650-z&amp;volume=11&amp;publication_year=2021&amp;author=Mateo-Garcia%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Qiu, S., Zhu, Z. &amp; Woodcock, C. E. Cirrus clouds that adversely affect Landsat 8 images: What are they and how to detect them? <i>Remote Sensing of Environment</i> <b>246</b>, 111884, <a href="https://doi.org/10.1016/j.rse.2020.111884" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2020.111884">https://doi.org/10.1016/j.rse.2020.111884</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2020.111884" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2020.111884" aria-label="Article reference 9" data-doi="10.1016/j.rse.2020.111884">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020RSEnv.246k1884Q" aria-label="ADS reference 9">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Cirrus%20clouds%20that%20adversely%20affect%20Landsat%208%20images%3A%20What%20are%20they%20and%20how%20to%20detect%20them%3F&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2020.111884&amp;volume=246&amp;publication_year=2020&amp;author=Qiu%2CS&amp;author=Zhu%2CZ&amp;author=Woodcock%2CCE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Foga, S. <i>et al</i>. Cloud detection algorithm comparison and validation for operational Landsat data products. <i>Remote Sensing of Environment</i> <b>194</b>, 379–390, <a href="https://doi.org/10.1016/j.rse.2017.03.026" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2017.03.026">https://doi.org/10.1016/j.rse.2017.03.026</a> (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2017.03.026" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2017.03.026" aria-label="Article reference 10" data-doi="10.1016/j.rse.2017.03.026">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2017RSEnv.194..379F" aria-label="ADS reference 10">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud%20detection%20algorithm%20comparison%20and%20validation%20for%20operational%20Landsat%20data%20products&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2017.03.026&amp;volume=194&amp;pages=379-390&amp;publication_year=2017&amp;author=Foga%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Qiu, S., Zhu, Z. &amp; He, B. Remote Sensing of Environment Fmask 4. 0: Improved cloud and cloud shadow detection in Landsats 4–8 and Sentinel-2 imagery. <i>Remote Sensing of Environment</i> <b>231</b>, 111205, <a href="https://doi.org/10.1016/j.rse.2019.05.024" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2019.05.024">https://doi.org/10.1016/j.rse.2019.05.024</a> (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2019.05.024" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2019.05.024" aria-label="Article reference 11" data-doi="10.1016/j.rse.2019.05.024">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2019RSEnv.231k1205Q" aria-label="ADS reference 11">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Remote%20Sensing%20of%20Environment%20Fmask%204.%200%3A%20Improved%20cloud%20and%20cloud%20shadow%20detection%20in%20Landsats%204%E2%80%938%20and%20Sentinel-2%20imagery&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2019.05.024&amp;volume=231&amp;publication_year=2019&amp;author=Qiu%2CS&amp;author=Zhu%2CZ&amp;author=He%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Louis, J. <i>et al</i>. Sentinel-2 SEN2COR: L2A processor for users. <i>European Space Agency, (Special Publication) ESA SP</i> <b>SP-740</b>, 9–13 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Sentinel-2%20SEN2COR%3A%20L2A%20processor%20for%20users&amp;journal=European%20Space%20Agency%2C%20%28Special%20Publication%29%20ESA%20SP&amp;volume=SP-740&amp;pages=9-13&amp;publication_year=2016&amp;author=Louis%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Sanchez, A. H. <i>et al</i>. Comparison of Cloud Cover Detection Algorithms on Sentinel–2 Images of the Amazon Tropical Forest. <i>Remote Sensing</i> <b>12</b>, 1284, <a href="https://doi.org/10.3390/rs12081284" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs12081284">https://doi.org/10.3390/rs12081284</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs12081284" data-track-action="article reference" href="https://doi.org/10.3390%2Frs12081284" aria-label="Article reference 13" data-doi="10.3390/rs12081284">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020RemS...12.1284S" aria-label="ADS reference 13">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparison%20of%20Cloud%20Cover%20Detection%20Algorithms%20on%20Sentinel%E2%80%932%20Images%20of%20the%20Amazon%20Tropical%20Forest&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs12081284&amp;volume=12&amp;publication_year=2020&amp;author=Sanchez%2CAH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Zekoll, V. <i>et al</i>. Comparison of masking algorithms for sentinel-2 imagery. <i>Remote Sensing</i> <b>13</b>, 1–21, <a href="https://doi.org/10.3390/rs13010137" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs13010137">https://doi.org/10.3390/rs13010137</a> (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs13010137" data-track-action="article reference" href="https://doi.org/10.3390%2Frs13010137" aria-label="Article reference 14" data-doi="10.3390/rs13010137">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparison%20of%20masking%20algorithms%20for%20sentinel-2%20imagery&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs13010137&amp;volume=13&amp;pages=1-21&amp;publication_year=2021&amp;author=Zekoll%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Cilli, R. <i>et al</i>. Machine Learning for Cloud Detection of Globally Distributed Sentinel-2 Images. <i>Remote Sensing</i> <b>12</b>, 2355, <a href="https://doi.org/10.3390/rs12152355" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs12152355">https://doi.org/10.3390/rs12152355</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs12152355" data-track-action="article reference" href="https://doi.org/10.3390%2Frs12152355" aria-label="Article reference 15" data-doi="10.3390/rs12152355">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020RemS...12.2355C" aria-label="ADS reference 15">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Machine%20Learning%20for%20Cloud%20Detection%20of%20Globally%20Distributed%20Sentinel-2%20Images&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs12152355&amp;volume=12&amp;publication_year=2020&amp;author=Cilli%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Melchiorre, A., Boschetti, L. &amp; Roy, D. P. Global evaluation of the suitability of MODIS-Terra detected cloud cover as a proxy for Landsat 7 cloud conditions. <i>Remote Sensing</i> <b>12</b>, 1–16, <a href="https://doi.org/10.3390/rs12020202" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs12020202">https://doi.org/10.3390/rs12020202</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs12020202" data-track-action="article reference" href="https://doi.org/10.3390%2Frs12020202" aria-label="Article reference 16" data-doi="10.3390/rs12020202">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Global%20evaluation%20of%20the%20suitability%20of%20MODIS-Terra%20detected%20cloud%20cover%20as%20a%20proxy%20for%20Landsat%207%20cloud%20conditions&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs12020202&amp;volume=12&amp;pages=1-16&amp;publication_year=2020&amp;author=Melchiorre%2CA&amp;author=Boschetti%2CL&amp;author=Roy%2CDP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Stillinger, T., Roberts, D. A., Collar, N. M. &amp; Dozier, J. Cloud Masking for Landsat 8 and MODIS Terra Over Snow-Covered Terrain: Error Analysis and Spectral Similarity Between Snow and Cloud. <i>Water Resources Research</i> <b>55</b>, 6169–6184, <a href="https://doi.org/10.1029/2019WR024932" data-track="click" data-track-action="external reference" data-track-label="10.1029/2019WR024932">https://doi.org/10.1029/2019WR024932</a> (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1029/2019WR024932" data-track-action="article reference" href="https://doi.org/10.1029%2F2019WR024932" aria-label="Article reference 17" data-doi="10.1029/2019WR024932">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2019WRR....55.6169S" aria-label="ADS reference 17">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud%20Masking%20for%20Landsat%208%20and%20MODIS%20Terra%20Over%20Snow-Covered%20Terrain%3A%20Error%20Analysis%20and%20Spectral%20Similarity%20Between%20Snow%20and%20Cloud&amp;journal=Water%20Resources%20Research&amp;doi=10.1029%2F2019WR024932&amp;volume=55&amp;pages=6169-6184&amp;publication_year=2019&amp;author=Stillinger%2CT&amp;author=Roberts%2CDA&amp;author=Collar%2CNM&amp;author=Dozier%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Zhu, X. X. <i>et al</i>. Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources. <i>IEEE Geoscience and Remote Sensing Magazine</i> <b>5</b>, 8–36, <a href="https://doi.org/10.1109/MGRS.2017.2762307" data-track="click" data-track-action="external reference" data-track-label="10.1109/MGRS.2017.2762307">https://doi.org/10.1109/MGRS.2017.2762307</a> (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/MGRS.2017.2762307" data-track-action="article reference" href="https://doi.org/10.1109%2FMGRS.2017.2762307" aria-label="Article reference 18" data-doi="10.1109/MGRS.2017.2762307">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20Learning%20in%20Remote%20Sensing%3A%20A%20Comprehensive%20Review%20and%20List%20of%20Resources&amp;journal=IEEE%20Geoscience%20and%20Remote%20Sensing%20Magazine&amp;doi=10.1109%2FMGRS.2017.2762307&amp;volume=5&amp;pages=8-36&amp;publication_year=2017&amp;author=Zhu%2CXX">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Wei, J. <i>et al</i>. Cloud detection for Landsat imagery by combining the random forest and superpixels extracted via energy-driven sampling segmentation approaches. <i>Remote Sensing of Environment</i> <b>248</b>, 112005, <a href="https://doi.org/10.1016/j.rse.2020.112005" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2020.112005">https://doi.org/10.1016/j.rse.2020.112005</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2020.112005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2020.112005" aria-label="Article reference 19" data-doi="10.1016/j.rse.2020.112005">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020RSEnv.248k2005W" aria-label="ADS reference 19">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud%20detection%20for%20Landsat%20imagery%20by%20combining%20the%20random%20forest%20and%20superpixels%20extracted%20via%20energy-driven%20sampling%20segmentation%20approaches&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2020.112005&amp;volume=248&amp;publication_year=2020&amp;author=Wei%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Bai, T., Li, D., Sun, K., Chen, Y. &amp; Li, W. Cloud detection for high-resolution satellite imagery using machine learning and multi-feature fusion. <i>Remote Sensing</i> <b>8</b>, 1–21, <a href="https://doi.org/10.3390/rs8090715" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs8090715">https://doi.org/10.3390/rs8090715</a> (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs8090715" data-track-action="article reference" href="https://doi.org/10.3390%2Frs8090715" aria-label="Article reference 20" data-doi="10.3390/rs8090715">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud%20detection%20for%20high-resolution%20satellite%20imagery%20using%20machine%20learning%20and%20multi-feature%20fusion&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs8090715&amp;volume=8&amp;pages=1-21&amp;publication_year=2016&amp;author=Bai%2CT&amp;author=Li%2CD&amp;author=Sun%2CK&amp;author=Chen%2CY&amp;author=Li%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Ghasemian, N. &amp; Akhoondzadeh, M. Introducing two Random Forest based methods for cloud detection in remote sensing images. <i>Advances in Space Research</i> <b>62</b>, 288–303, <a href="https://doi.org/10.1016/j.asr.2018.04.030" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.asr.2018.04.030">https://doi.org/10.1016/j.asr.2018.04.030</a> (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.asr.2018.04.030" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.asr.2018.04.030" aria-label="Article reference 21" data-doi="10.1016/j.asr.2018.04.030">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2018AdSpR..62..288G" aria-label="ADS reference 21">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Introducing%20two%20Random%20Forest%20based%20methods%20for%20cloud%20detection%20in%20remote%20sensing%20images&amp;journal=Advances%20in%20Space%20Research&amp;doi=10.1016%2Fj.asr.2018.04.030&amp;volume=62&amp;pages=288-303&amp;publication_year=2018&amp;author=Ghasemian%2CN&amp;author=Akhoondzadeh%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Zupanc, A. Improving Cloud Detection with Machine Learning (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">López-Puigdollers, D., Mateo-García, G. &amp; Gómez-Chova, L. Benchmarking deep learning models for cloud detection in landsat-8 and sentinel-2 images. <i>Remote Sensing</i> <b>13</b>, 1–20, <a href="https://doi.org/10.3390/rs13050992" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs13050992">https://doi.org/10.3390/rs13050992</a> (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs13050992" data-track-action="article reference" href="https://doi.org/10.3390%2Frs13050992" aria-label="Article reference 23" data-doi="10.3390/rs13050992">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Benchmarking%20deep%20learning%20models%20for%20cloud%20detection%20in%20landsat-8%20and%20sentinel-2%20images&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs13050992&amp;volume=13&amp;pages=1-20&amp;publication_year=2021&amp;author=L%C3%B3pez-Puigdollers%2CD&amp;author=Mateo-Garc%C3%ADa%2CG&amp;author=G%C3%B3mez-Chova%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Skakun, S. <i>et al</i>. Cloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2. <i>Remote Sensing of Environment</i> <b>274</b>, 112990, <a href="https://doi.org/10.1016/j.rse.2022.112990" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2022.112990">https://doi.org/10.1016/j.rse.2022.112990</a> (2022).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2022.112990" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2022.112990" aria-label="Article reference 24" data-doi="10.1016/j.rse.2022.112990">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2022RSEnv.274k2990S" aria-label="ADS reference 24">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud%20Mask%20Intercomparison%20eXercise%20%28CMIX%29%3A%20An%20evaluation%20of%20cloud%20masking%20algorithms%20for%20Landsat%208%20and%20Sentinel-2&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2022.112990&amp;volume=274&amp;publication_year=2022&amp;author=Skakun%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Li, L., Li, X., Jiang, L., Su, X. &amp; Chen, F. A review on deep learning techniques for cloud detection methodologies and challenges. <i>Signal, Image and Video Processing</i> <a href="https://doi.org/10.1007/s11760-021-01885-7" data-track="click" data-track-action="external reference" data-track-label="10.1007/s11760-021-01885-7">https://doi.org/10.1007/s11760-021-01885-7</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Mahajan, S. &amp; Fataniya, B. Cloud detection methodologies: variants and development–a review. <i>Complex &amp; Intelligent Systems</i> <b>6</b>, 251–261, <a href="https://doi.org/10.1007/s40747-019-00128-0" data-track="click" data-track-action="external reference" data-track-label="10.1007/s40747-019-00128-0">https://doi.org/10.1007/s40747-019-00128-0</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="noopener" data-track-label="10.1007/s40747-019-00128-0" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s40747-019-00128-0" aria-label="Article reference 26" data-doi="10.1007/s40747-019-00128-0">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud%20detection%20methodologies%3A%20variants%20and%20development%E2%80%93a%20review&amp;journal=Complex%20%26%20Intelligent%20Systems&amp;doi=10.1007%2Fs40747-019-00128-0&amp;volume=6&amp;pages=251-261&amp;publication_year=2020&amp;author=Mahajan%2CS&amp;author=Fataniya%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Hughes, M. J. &amp; Kennedy, R. High-quality cloud masking of landsat 8 imagery using convolutional neural networks. <i>Remote Sensing</i> <b>11</b>, <a href="https://doi.org/10.3390/rs11212591" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs11212591">https://doi.org/10.3390/rs11212591</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Hollstein, A., Segl, K., Guanter, L., Brell, M. &amp; Enesco, M. Ready-to-use methods for the detection of clouds, cirrus, snow, shadow, water and clear sky pixels in Sentinel-2 MSI images. <i>Remote Sensing</i> <b>8</b>, 1–18, <a href="https://doi.org/10.3390/rs8080666" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs8080666">https://doi.org/10.3390/rs8080666</a> (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs8080666" data-track-action="article reference" href="https://doi.org/10.3390%2Frs8080666" aria-label="Article reference 28" data-doi="10.3390/rs8080666">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Ready-to-use%20methods%20for%20the%20detection%20of%20clouds%2C%20cirrus%2C%20snow%2C%20shadow%2C%20water%20and%20clear%20sky%20pixels%20in%20Sentinel-2%20MSI%20images&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs8080666&amp;volume=8&amp;pages=1-18&amp;publication_year=2016&amp;author=Hollstein%2CA&amp;author=Segl%2CK&amp;author=Guanter%2CL&amp;author=Brell%2CM&amp;author=Enesco%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Mohajerani, S. &amp; Saeedi, P. Cloud-Net: An End-To-End Cloud Detection Algorithm for Landsat 8 Imagery. <i>International Geoscience and Remote Sensing Symposium (IGARSS)</i> 1029–1032, <a href="https://doi.org/10.1109/IGARSS.2019.8898776" data-track="click" data-track-action="external reference" data-track-label="10.1109/IGARSS.2019.8898776">https://doi.org/10.1109/IGARSS.2019.8898776</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Baetens, L., Desjardins, C. &amp; Hagolle, O. Validation of copernicus Sentinel-2 cloud masks obtained from MAJA, Sen2Cor, and FMask processors using reference cloud masks generated with a supervised active learning procedure. <i>Remote Sensing</i> <b>11</b>, 1–25, <a href="https://doi.org/10.3390/rs11040433" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs11040433">https://doi.org/10.3390/rs11040433</a> (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs11040433" data-track-action="article reference" href="https://doi.org/10.3390%2Frs11040433" aria-label="Article reference 30" data-doi="10.3390/rs11040433">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Validation%20of%20copernicus%20Sentinel-2%20cloud%20masks%20obtained%20from%20MAJA%2C%20Sen2Cor%2C%20and%20FMask%20processors%20using%20reference%20cloud%20masks%20generated%20with%20a%20supervised%20active%20learning%20procedure&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs11040433&amp;volume=11&amp;pages=1-25&amp;publication_year=2019&amp;author=Baetens%2CL&amp;author=Desjardins%2CC&amp;author=Hagolle%2CO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Mohajerani, S. &amp; Saeedi, P. Cloud-Net+: A cloud segmentation CNN for landsat 8 remote sensing imagery optimized with filtered jaccard loss function. <i>arXiv</i> 1–12 (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Francis, A., Mrziglod, J., Sidiropoulos, P. &amp; Muller, J.-P. Sentinel-2 Cloud Mask Catalogue, <a href="https://doi.org/10.5281/zenodo.4172871" data-track="click" data-track-action="external reference" data-track-label="10.5281/zenodo.4172871">https://doi.org/10.5281/zenodo.4172871</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Cordts, M. <i>et al</i>. The Cityscapes Dataset for Semantic Urban Scene Understanding. <i>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</i> <b>2016-Decem</b>, 3213–3223, <a href="https://doi.org/10.1109/CVPR.2016.350" data-track="click" data-track-action="external reference" data-track-label="10.1109/CVPR.2016.350">https://doi.org/10.1109/CVPR.2016.350</a> (2016).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Zhu, X. X. <i>et al</i>. So2Sat LCZ42: A Benchmark Dataset for Global Local Climate Zones Classification. <i>arXiv</i> <b>14</b>, 2–13 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=So2Sat%20LCZ42%3A%20A%20Benchmark%20Dataset%20for%20Global%20Local%20Climate%20Zones%20Classification&amp;journal=arXiv&amp;volume=14&amp;pages=2-13&amp;publication_year=2019&amp;author=Zhu%2CXX">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Meraner, A., Ebel, P., Zhu, X. X. &amp; Schmitt, M. Cloud removal in Sentinel-2 imagery using a deep residual neural network and SAR-optical data fusion. <i>ISPRS Journal of Photogrammetry and Remote Sensing</i> <b>166</b>, 333–346, <a href="https://doi.org/10.1016/j.isprsjprs.2020.05.013" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.isprsjprs.2020.05.013">https://doi.org/10.1016/j.isprsjprs.2020.05.013</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.isprsjprs.2020.05.013" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.isprsjprs.2020.05.013" aria-label="Article reference 35" data-doi="10.1016/j.isprsjprs.2020.05.013">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020JPRS..166..333M" aria-label="ADS reference 35">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud%20removal%20in%20Sentinel-2%20imagery%20using%20a%20deep%20residual%20neural%20network%20and%20SAR-optical%20data%20fusion&amp;journal=ISPRS%20Journal%20of%20Photogrammetry%20and%20Remote%20Sensing&amp;doi=10.1016%2Fj.isprsjprs.2020.05.013&amp;volume=166&amp;pages=333-346&amp;publication_year=2020&amp;author=Meraner%2CA&amp;author=Ebel%2CP&amp;author=Zhu%2CXX&amp;author=Schmitt%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Singh, P. &amp; Komodakis, N. Cloud-GAN: Cloud removal for sentinel-2 imagery using a cyclic consistent generative adversarial networks. <i>International Geoscience and Remote Sensing Symposium (IGARSS)</i> <b>2018-July</b>, 1772–1775, <a href="https://doi.org/10.1109/IGARSS.2018.8519033" data-track="click" data-track-action="external reference" data-track-label="10.1109/IGARSS.2018.8519033">https://doi.org/10.1109/IGARSS.2018.8519033</a> (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/IGARSS.2018.8519033" data-track-action="article reference" href="https://doi.org/10.1109%2FIGARSS.2018.8519033" aria-label="Article reference 36" data-doi="10.1109/IGARSS.2018.8519033">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud-GAN%3A%20Cloud%20removal%20for%20sentinel-2%20imagery%20using%20a%20cyclic%20consistent%20generative%20adversarial%20networks&amp;journal=International%20Geoscience%20and%20Remote%20Sensing%20Symposium%20%28IGARSS%29&amp;doi=10.1109%2FIGARSS.2018.8519033&amp;volume=2018-July&amp;pages=1772-1775&amp;publication_year=2018&amp;author=Singh%2CP&amp;author=Komodakis%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Gorelick, N. <i>et al</i>. Google Earth Engine: Planetary-scale geospatial analysis for everyone. <i>Remote Sensing of Environment</i> <b>202</b>, 18–27, <a href="https://doi.org/10.1016/j.rse.2017.06.031" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2017.06.031">https://doi.org/10.1016/j.rse.2017.06.031</a> (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2017.06.031" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2017.06.031" aria-label="Article reference 37" data-doi="10.1016/j.rse.2017.06.031">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2017RSEnv.202...18G" aria-label="ADS reference 37">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Google%20Earth%20Engine%3A%20Planetary-scale%20geospatial%20analysis%20for%20everyone&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2017.06.031&amp;volume=202&amp;pages=18-27&amp;publication_year=2017&amp;author=Gorelick%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Yamazaki, D. <i>et al</i>. MERIT Hydro: A High-Resolution Global Hydrography Map Based on Latest Topography Dataset. <i>Water Resources Research</i> <b>55</b>, 5053–5073, <a href="https://doi.org/10.1029/2019WR024873" data-track="click" data-track-action="external reference" data-track-label="10.1029/2019WR024873">https://doi.org/10.1029/2019WR024873</a> (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1029/2019WR024873" data-track-action="article reference" href="https://doi.org/10.1029%2F2019WR024873" aria-label="Article reference 38" data-doi="10.1029/2019WR024873">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2019WRR....55.5053Y" aria-label="ADS reference 38">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=MERIT%20Hydro%3A%20A%20High-Resolution%20Global%20Hydrography%20Map%20Based%20on%20Latest%20Topography%20Dataset&amp;journal=Water%20Resources%20Research&amp;doi=10.1029%2F2019WR024873&amp;volume=55&amp;pages=5053-5073&amp;publication_year=2019&amp;author=Yamazaki%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Pekel, J. F., Cottam, A., Gorelick, N. &amp; Belward, A. S. High-resolution mapping of global surface water and its long-term changes. <i>Nature</i> <b>540</b>, 418–422, <a href="https://doi.org/10.1038/nature20584" data-track="click" data-track-action="external reference" data-track-label="10.1038/nature20584">https://doi.org/10.1038/nature20584</a> (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature20584" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature20584" aria-label="Article reference 39" data-doi="10.1038/nature20584">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2016Natur.540..418P" aria-label="ADS reference 39">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28XitVWmurbJ" aria-label="CAS reference 39">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=High-resolution%20mapping%20of%20global%20surface%20water%20and%20its%20long-term%20changes&amp;journal=Nature&amp;doi=10.1038%2Fnature20584&amp;volume=540&amp;pages=418-422&amp;publication_year=2016&amp;author=Pekel%2CJF&amp;author=Cottam%2CA&amp;author=Gorelick%2CN&amp;author=Belward%2CAS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Buchhorn, M. <i>et al</i>. Copernicus Global Land Service: Land Cover 100 m: Collection 3: epoch 2015: Globe (Version V3.0.1). <i>Zenodo</i> 1–14 (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Frantz, D., Haß, E., Uhl, A., Stoffels, J. &amp; Hill, J. Improvement of the Fmask algorithm for Sentinel-2 images: Separating clouds from bright surfaces based on parallax effects. <i>Remote Sensing of Environment</i> <b>215</b>, 471–481, <a href="https://doi.org/10.1016/j.rse.2018.04.046" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2018.04.046">https://doi.org/10.1016/j.rse.2018.04.046</a> (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2018.04.046" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2018.04.046" aria-label="Article reference 41" data-doi="10.1016/j.rse.2018.04.046">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2018RSEnv.215..471F" aria-label="ADS reference 41">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Improvement%20of%20the%20Fmask%20algorithm%20for%20Sentinel-2%20images%3A%20Separating%20clouds%20from%20bright%20surfaces%20based%20on%20parallax%20effects&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2018.04.046&amp;volume=215&amp;pages=471-481&amp;publication_year=2018&amp;author=Frantz%2CD&amp;author=Ha%C3%9F%2CE&amp;author=Uhl%2CA&amp;author=Stoffels%2CJ&amp;author=Hill%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Fernandez-Moran, R., Gómez-Chova, L., Alonso, L., Mateo-García, G. &amp; López-Puigdollers, D. Towards a novel approach for Sentinel-3 synergistic OLCI/SLSTR cloud and cloud shadow detection based on stereo cloud-top height estimation. <i>ISPRS Journal of Photogrammetry and Remote Sensing</i> <b>181</b>, 238–253, <a href="https://doi.org/10.1016/j.isprsjprs.2021.09.013" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.isprsjprs.2021.09.013">https://doi.org/10.1016/j.isprsjprs.2021.09.013</a> (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.isprsjprs.2021.09.013" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.isprsjprs.2021.09.013" aria-label="Article reference 42" data-doi="10.1016/j.isprsjprs.2021.09.013">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2021JPRS..181..238F" aria-label="ADS reference 42">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20a%20novel%20approach%20for%20Sentinel-3%20synergistic%20OLCI%2FSLSTR%20cloud%20and%20cloud%20shadow%20detection%20based%20on%20stereo%20cloud-top%20height%20estimation&amp;journal=ISPRS%20Journal%20of%20Photogrammetry%20and%20Remote%20Sensing&amp;doi=10.1016%2Fj.isprsjprs.2021.09.013&amp;volume=181&amp;pages=238-253&amp;publication_year=2021&amp;author=Fernandez-Moran%2CR&amp;author=G%C3%B3mez-Chova%2CL&amp;author=Alonso%2CL&amp;author=Mateo-Garc%C3%ADa%2CG&amp;author=L%C3%B3pez-Puigdollers%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Tiede, D., Sudmanns, M., Augustin, H. &amp; Baraldi, A. Investigating ESA Sentinel-2 products’ systematic cloud cover overestimation in very high altitude areas. <i>Remote Sensing of Environment</i> <b>252</b>, 112163, <a href="https://doi.org/10.1016/j.rse.2020.112163" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2020.112163">https://doi.org/10.1016/j.rse.2020.112163</a> (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2020.112163" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2020.112163" aria-label="Article reference 43" data-doi="10.1016/j.rse.2020.112163">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2021RSEnv.252k2163T" aria-label="ADS reference 43">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Investigating%20ESA%20Sentinel-2%20products%E2%80%99%20systematic%20cloud%20cover%20overestimation%20in%20very%20high%20altitude%20areas&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2020.112163&amp;volume=252&amp;publication_year=2021&amp;author=Tiede%2CD&amp;author=Sudmanns%2CM&amp;author=Augustin%2CH&amp;author=Baraldi%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">Rittger, K. <i>et al</i>. Canopy Adjustment and Improved Cloud Detection for Remotely Sensed Snow Cover Mapping. <i>Water Resources Research</i> <b>56</b>, 1–20, <a href="https://doi.org/10.1029/2019WR024914" data-track="click" data-track-action="external reference" data-track-label="10.1029/2019WR024914">https://doi.org/10.1029/2019WR024914</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1029/2019WR024914" data-track-action="article reference" href="https://doi.org/10.1029%2F2019WR024914" aria-label="Article reference 44" data-doi="10.1029/2019WR024914">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Canopy%20Adjustment%20and%20Improved%20Cloud%20Detection%20for%20Remotely%20Sensed%20Snow%20Cover%20Mapping&amp;journal=Water%20Resources%20Research&amp;doi=10.1029%2F2019WR024914&amp;volume=56&amp;pages=1-20&amp;publication_year=2020&amp;author=Rittger%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">Castillo-Navarro, J., Saux, B. L., Boulch, A., Audebert, N. &amp; Lefèvre, S. Semi-Supervised Semantic Segmentation in Earth Observation: The MiniFrance Suite, Dataset Analysis and Multi-task Network Study. <i>arxiv</i> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Li, Y. <i>et al</i>. Accurate cloud detection in high-resolution remote sensing imagery by weakly supervised deep learning. <i>Remote Sensing of Environment</i> <b>250</b>, 112045, <a href="https://doi.org/10.1016/j.rse.2020.112045" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.rse.2020.112045">https://doi.org/10.1016/j.rse.2020.112045</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.rse.2020.112045" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.rse.2020.112045" aria-label="Article reference 46" data-doi="10.1016/j.rse.2020.112045">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020RSEnv.250k2045L" aria-label="ADS reference 46">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Accurate%20cloud%20detection%20in%20high-resolution%20remote%20sensing%20imagery%20by%20weakly%20supervised%20deep%20learning&amp;journal=Remote%20Sensing%20of%20Environment&amp;doi=10.1016%2Fj.rse.2020.112045&amp;volume=250&amp;publication_year=2020&amp;author=Li%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47."><p class="c-article-references__text" id="ref-CR47">Valdez, C., Ziefle, M. &amp; Sedlmair, M. A Framework for Studying Biases in Visualization Research. <i>VIS 2017: Dealing with Cognitive Biases in Visualisations</i> (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48."><p class="c-article-references__text" id="ref-CR48">Mrziglod, J. IRIS - Intelligence foR Image Segmentation (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49."><p class="c-article-references__text" id="ref-CR49">Friedman, J. H. Greedy function approximation: a gradient boosting machine. <i>Annals of statistics</i> 1189–1232 (2001).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50."><p class="c-article-references__text" id="ref-CR50">Ke, G. <i>et al</i>. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In Guyon, I. <i>et al</i>. (eds.) <i>Advances in Neural Information Processing Systems</i>, vol. 30 (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51."><p class="c-article-references__text" id="ref-CR51">Mejia, F. A. <i>et al</i>. Coupling sky images with radiative transfer models: a new method to estimate cloud optical depth. <i>Atmospheric Measurement Techniques</i> <b>9</b>, 4151–4165 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.5194/amt-9-4151-2016" data-track-action="article reference" href="https://doi.org/10.5194%2Famt-9-4151-2016" aria-label="Article reference 51" data-doi="10.5194/amt-9-4151-2016">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2016AMT.....9.4151M" aria-label="ADS reference 51">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Coupling%20sky%20images%20with%20radiative%20transfer%20models%3A%20a%20new%20method%20to%20estimate%20cloud%20optical%20depth&amp;journal=Atmospheric%20Measurement%20Techniques&amp;doi=10.5194%2Famt-9-4151-2016&amp;volume=9&amp;pages=4151-4165&amp;publication_year=2016&amp;author=Mejia%2CFA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52."><p class="c-article-references__text" id="ref-CR52">Mateo-García, G., Laparra, V., López-Puigdollers, D. &amp; Gómez-Chova, L. Transferring deep learning models for cloud detection between Landsat-8 and Proba-V. <i>ISPRS Journal of Photogrammetry and Remote Sensing</i> <b>160</b>, 1–17, <a href="https://doi.org/10.1016/j.isprsjprs.2019.11.024" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.isprsjprs.2019.11.024">https://doi.org/10.1016/j.isprsjprs.2019.11.024</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.isprsjprs.2019.11.024" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.isprsjprs.2019.11.024" aria-label="Article reference 52" data-doi="10.1016/j.isprsjprs.2019.11.024">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020JPRS..160....1M" aria-label="ADS reference 52">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Transferring%20deep%20learning%20models%20for%20cloud%20detection%20between%20Landsat-8%20and%20Proba-V&amp;journal=ISPRS%20Journal%20of%20Photogrammetry%20and%20Remote%20Sensing&amp;doi=10.1016%2Fj.isprsjprs.2019.11.024&amp;volume=160&amp;pages=1-17&amp;publication_year=2020&amp;author=Mateo-Garc%C3%ADa%2CG&amp;author=Laparra%2CV&amp;author=L%C3%B3pez-Puigdollers%2CD&amp;author=G%C3%B3mez-Chova%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53."><p class="c-article-references__text" id="ref-CR53">Mateo-García, G., Laparra, V., López-Puigdollers, D. &amp; Gómez-Chova, L. Cross-Sensor Adversarial Domain Adaptation of Landsat-8 and Proba-V Images for Cloud Detection. <i>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</i> <b>14</b>, 747–761, <a href="https://doi.org/10.1109/JSTARS.2020.3031741" data-track="click" data-track-action="external reference" data-track-label="10.1109/JSTARS.2020.3031741">https://doi.org/10.1109/JSTARS.2020.3031741</a> (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/JSTARS.2020.3031741" data-track-action="article reference" href="https://doi.org/10.1109%2FJSTARS.2020.3031741" aria-label="Article reference 53" data-doi="10.1109/JSTARS.2020.3031741">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2021IJSTA..14..747M" aria-label="ADS reference 53">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=Cross-Sensor%20Adversarial%20Domain%20Adaptation%20of%20Landsat-8%20and%20Proba-V%20Images%20for%20Cloud%20Detection&amp;journal=IEEE%20Journal%20of%20Selected%20Topics%20in%20Applied%20Earth%20Observations%20and%20Remote%20Sensing&amp;doi=10.1109%2FJSTARS.2020.3031741&amp;volume=14&amp;pages=747-761&amp;publication_year=2021&amp;author=Mateo-Garc%C3%ADa%2CG&amp;author=Laparra%2CV&amp;author=L%C3%B3pez-Puigdollers%2CD&amp;author=G%C3%B3mez-Chova%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54."><p class="c-article-references__text" id="ref-CR54">Domnich, M. <i>et al</i>. KappaMask: Ai-based cloudmask processor for sentinel-2. <i>Remote Sensing</i> <b>13</b>, <a href="https://doi.org/10.3390/rs13204100" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs13204100">https://doi.org/10.3390/rs13204100</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55."><p class="c-article-references__text" id="ref-CR55">Valavi, R., Elith, J., Lahoz-Monfort, J. J. &amp; Guillera-Arroita, G. blockCV: An r package for generating spatially or environmentally separated folds for k-fold cross-validation of species distribution models. <i>Methods in Ecology and Evolution</i> <b>10</b>, 225–232, <a href="https://doi.org/10.1111/2041-210X.13107" data-track="click" data-track-action="external reference" data-track-label="10.1111/2041-210X.13107">https://doi.org/10.1111/2041-210X.13107</a> (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/2041-210X.13107" data-track-action="article reference" href="https://doi.org/10.1111%2F2041-210X.13107" aria-label="Article reference 55" data-doi="10.1111/2041-210X.13107">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=blockCV%3A%20An%20r%20package%20for%20generating%20spatially%20or%20environmentally%20separated%20folds%20for%20k-fold%20cross-validation%20of%20species%20distribution%20models&amp;journal=Methods%20in%20Ecology%20and%20Evolution&amp;doi=10.1111%2F2041-210X.13107&amp;volume=10&amp;pages=225-232&amp;publication_year=2019&amp;author=Valavi%2CR&amp;author=Elith%2CJ&amp;author=Lahoz-Monfort%2CJJ&amp;author=Guillera-Arroita%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56."><p class="c-article-references__text" id="ref-CR56">Roberts, D. R. <i>et al</i>. Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure. <i>Ecography</i> <b>40</b>, 913–929, <a href="https://doi.org/10.1111/ecog.02881" data-track="click" data-track-action="external reference" data-track-label="10.1111/ecog.02881">https://doi.org/10.1111/ecog.02881</a> (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/ecog.02881" data-track-action="article reference" href="https://doi.org/10.1111%2Fecog.02881" aria-label="Article reference 56" data-doi="10.1111/ecog.02881">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Cross-validation%20strategies%20for%20data%20with%20temporal%2C%20spatial%2C%20hierarchical%2C%20or%20phylogenetic%20structure&amp;journal=Ecography&amp;doi=10.1111%2Fecog.02881&amp;volume=40&amp;pages=913-929&amp;publication_year=2017&amp;author=Roberts%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57."><p class="c-article-references__text" id="ref-CR57">Luis, C. <i>et al</i>. CloudSEN12 - a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2. <i>Science Data Bank</i> <a href="https://doi.org/10.57760/sciencedb.06669" data-track="click" data-track-action="external reference" data-track-label="10.57760/sciencedb.06669">https://doi.org/10.57760/sciencedb.06669</a> (2022).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58."><p class="c-article-references__text" id="ref-CR58">Iosifescu Enescu, I. <i>et al</i>. Cloud optimized raster encoding (core): A web-native streamable format for large environmental time series. <i>Geomatics</i> <b>1</b>, 369–382 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/geomatics1030021" data-track-action="article reference" href="https://doi.org/10.3390%2Fgeomatics1030021" aria-label="Article reference 58" data-doi="10.3390/geomatics1030021">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=Cloud%20optimized%20raster%20encoding%20%28core%29%3A%20A%20web-native%20streamable%20format%20for%20large%20environmental%20time%20series&amp;journal=Geomatics&amp;doi=10.3390%2Fgeomatics1030021&amp;volume=1&amp;pages=369-382&amp;publication_year=2021&amp;author=Iosifescu%20Enescu%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59."><p class="c-article-references__text" id="ref-CR59">Ronneberger, O., Fischer, P. &amp; Brox, T. U-net: Convolutional networks for biomedical image segmentation. In <i>International Conference on Medical image computing and computer-assisted intervention</i>, 234–241 (Springer, 2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="60."><p class="c-article-references__text" id="ref-CR60">Sandler, M., Howard, A., Zhu, M., Zhmoginov, A. &amp; Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. In <i>Proceedings of the IEEE conference on computer vision and pattern recognition</i>, 4510–4520 (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="61."><p class="c-article-references__text" id="ref-CR61">Paszke, A. <i>et al</i>. Pytorch: An imperative style, high-performance deep learning library. In Wallach, H. <i>et al</i>. (eds.) <i>Advances in Neural Information Processing Systems</i> <b>32</b>, 8024–8035 (Curran Associates, Inc., 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="62."><p class="c-article-references__text" id="ref-CR62">European Space Agency. CEOS-WGCV ACIX II CMIX Atmospheric Correction Inter-comparison Exercise Cloud Masking Inter-comparison Exercise 2nd workshop (2019). Online; accessed 14 October 2021.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="63."><p class="c-article-references__text" id="ref-CR63">Paperin, M., Wevers, J., Stelzer, K. &amp; Brockmann, C. PixBox Sentinel-2 pixel collection for CMIX. <i>Zenodo</i> <a href="https://doi.org/10.5281/zenodo.5036991" data-track="click" data-track-action="external reference" data-track-label="10.5281/zenodo.5036991">https://doi.org/10.5281/zenodo.5036991</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="64."><p class="c-article-references__text" id="ref-CR64">Schmitt, A. &amp; Wendleder, A. SAR-sharpening in the Kennaugh framework applied to the fusion of multi-modal SAR and optical images. <i>ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences</i> <b>4</b>, 133–140, <a href="https://doi.org/10.5194/isprs-annals-IV-1-133-2018" data-track="click" data-track-action="external reference" data-track-label="10.5194/isprs-annals-IV-1-133-2018">https://doi.org/10.5194/isprs-annals-IV-1-133-2018</a> (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.5194/isprs-annals-IV-1-133-2018" data-track-action="article reference" href="https://doi.org/10.5194%2Fisprs-annals-IV-1-133-2018" aria-label="Article reference 64" data-doi="10.5194/isprs-annals-IV-1-133-2018">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=SAR-sharpening%20in%20the%20Kennaugh%20framework%20applied%20to%20the%20fusion%20of%20multi-modal%20SAR%20and%20optical%20images&amp;journal=ISPRS%20Annals%20of%20the%20Photogrammetry%2C%20Remote%20Sensing%20and%20Spatial%20Information%20Sciences&amp;doi=10.5194%2Fisprs-annals-IV-1-133-2018&amp;volume=4&amp;pages=133-140&amp;publication_year=2018&amp;author=Schmitt%2CA&amp;author=Wendleder%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="65."><p class="c-article-references__text" id="ref-CR65">Schmitt, M., Hughes, L. H., Körner, M. &amp; Zhu, X. X. Colorizing sentinel-1 SAR images using a variational autoencoder conditioned on Sentinel-2 imagery. <i>International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives</i> <b>42</b>, 1045–1051, <a href="https://doi.org/10.5194/isprs-archives-XLII-2-1045-2018" data-track="click" data-track-action="external reference" data-track-label="10.5194/isprs-archives-XLII-2-1045-2018">https://doi.org/10.5194/isprs-archives-XLII-2-1045-2018</a> (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.5194/isprs-archives-XLII-2-1045-2018" data-track-action="article reference" href="https://doi.org/10.5194%2Fisprs-archives-XLII-2-1045-2018" aria-label="Article reference 65" data-doi="10.5194/isprs-archives-XLII-2-1045-2018">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2018ISPAr.422.1045S" aria-label="ADS reference 65">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=Colorizing%20sentinel-1%20SAR%20images%20using%20a%20variational%20autoencoder%20conditioned%20on%20Sentinel-2%20imagery&amp;journal=International%20Archives%20of%20the%20Photogrammetry%2C%20Remote%20Sensing%20and%20Spatial%20Information%20Sciences%20-%20ISPRS%20Archives&amp;doi=10.5194%2Fisprs-archives-XLII-2-1045-2018&amp;volume=42&amp;pages=1045-1051&amp;publication_year=2018&amp;author=Schmitt%2CM&amp;author=Hughes%2CLH&amp;author=K%C3%B6rner%2CM&amp;author=Zhu%2CXX">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="66."><p class="c-article-references__text" id="ref-CR66">Hughes, L. H., Schmitt, M., Mou, L., Wang, Y. &amp; Zhu, X. X. Identifying Corresponding Patches in SAR and Optical Images with a Pseudo-Siamese CNN. <i>IEEE Geoscience and Remote Sensing Letters</i> <b>15</b>, 784–788, <a href="https://doi.org/10.1109/LGRS.2018.2799232" data-track="click" data-track-action="external reference" data-track-label="10.1109/LGRS.2018.2799232">https://doi.org/10.1109/LGRS.2018.2799232</a> (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/LGRS.2018.2799232" data-track-action="article reference" href="https://doi.org/10.1109%2FLGRS.2018.2799232" aria-label="Article reference 66" data-doi="10.1109/LGRS.2018.2799232">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2018IGRSL..15..784H" aria-label="ADS reference 66">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 66" href="http://scholar.google.com/scholar_lookup?&amp;title=Identifying%20Corresponding%20Patches%20in%20SAR%20and%20Optical%20Images%20with%20a%20Pseudo-Siamese%20CNN&amp;journal=IEEE%20Geoscience%20and%20Remote%20Sensing%20Letters&amp;doi=10.1109%2FLGRS.2018.2799232&amp;volume=15&amp;pages=784-788&amp;publication_year=2018&amp;author=Hughes%2CLH&amp;author=Schmitt%2CM&amp;author=Mou%2CL&amp;author=Wang%2CY&amp;author=Zhu%2CXX">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="67."><p class="c-article-references__text" id="ref-CR67">Aybar, C., Wu, Q., Bautista, L., Yali, R. &amp; Barja, A. rgee: An R package for interacting with Google Earth Engine. <i>Journal of Open Source Software</i> <b>5</b>, 2272, <a href="https://doi.org/10.21105/joss.02272" data-track="click" data-track-action="external reference" data-track-label="10.21105/joss.02272">https://doi.org/10.21105/joss.02272</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.21105/joss.02272" data-track-action="article reference" href="https://doi.org/10.21105%2Fjoss.02272" aria-label="Article reference 67" data-doi="10.21105/joss.02272">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020JOSS....5.2272A" aria-label="ADS reference 67">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="http://scholar.google.com/scholar_lookup?&amp;title=rgee%3A%20An%20R%20package%20for%20interacting%20with%20Google%20Earth%20Engine&amp;journal=Journal%20of%20Open%20Source%20Software&amp;doi=10.21105%2Fjoss.02272&amp;volume=5&amp;publication_year=2020&amp;author=Aybar%2CC&amp;author=Wu%2CQ&amp;author=Bautista%2CL&amp;author=Yali%2CR&amp;author=Barja%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="68."><p class="c-article-references__text" id="ref-CR68">Pebesma, E. Simple features for R: Standardized support for spatial vector data. <i>R Journal</i> <b>10</b>, 439–446, <a href="https://doi.org/10.32614/rj-2018-009" data-track="click" data-track-action="external reference" data-track-label="10.32614/rj-2018-009">https://doi.org/10.32614/rj-2018-009</a> (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.32614/rj-2018-009" data-track-action="article reference" href="https://doi.org/10.32614%2Frj-2018-009" aria-label="Article reference 68" data-doi="10.32614/rj-2018-009">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 68" href="http://scholar.google.com/scholar_lookup?&amp;title=Simple%20features%20for%20R%3A%20Standardized%20support%20for%20spatial%20vector%20data&amp;journal=R%20Journal&amp;doi=10.32614%2Frj-2018-009&amp;volume=10&amp;pages=439-446&amp;publication_year=2018&amp;author=Pebesma%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="69."><p class="c-article-references__text" id="ref-CR69">Hijmans, R. J. <i>et al</i>. Package ‘raster’. <i>R package</i> <b>734</b> (2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="70."><p class="c-article-references__text" id="ref-CR70">Pebesma, E. stars: Spatiotemporal arrays, raster and vector data cubes. <i>R package version 0.4–1 ed2020</i> <a href="https://CRAN.R-project.org/package=stars" data-track="click" data-track-action="external reference" data-track-label="https://CRAN.R-project.org/package=stars">https://CRAN.R-project.org/package=stars</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="71."><p class="c-article-references__text" id="ref-CR71">Harris, C. R. <i>et al</i>. Array programming with numpy. <i>Nature</i> <b>585</b>, 357–362 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-020-2649-2" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-020-2649-2" aria-label="Article reference 71" data-doi="10.1038/s41586-020-2649-2">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020Natur.585..357H" aria-label="ADS reference 71">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXitlWmsbbN" aria-label="CAS reference 71">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 71" href="http://scholar.google.com/scholar_lookup?&amp;title=Array%20programming%20with%20numpy&amp;journal=Nature&amp;doi=10.1038%2Fs41586-020-2649-2&amp;volume=585&amp;pages=357-362&amp;publication_year=2020&amp;author=Harris%2CCR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="72."><p class="c-article-references__text" id="ref-CR72">Grolemund, G. &amp; Wickham, H. Dates and times made easy with lubridate. <i>Journal of statistical software</i> <b>40</b>, 1–25 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.18637/jss.v040.i03" data-track-action="article reference" href="https://doi.org/10.18637%2Fjss.v040.i03" aria-label="Article reference 72" data-doi="10.18637/jss.v040.i03">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 72" href="http://scholar.google.com/scholar_lookup?&amp;title=Dates%20and%20times%20made%20easy%20with%20lubridate&amp;journal=Journal%20of%20statistical%20software&amp;doi=10.18637%2Fjss.v040.i03&amp;volume=40&amp;pages=1-25&amp;publication_year=2011&amp;author=Grolemund%2CG&amp;author=Wickham%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="73."><p class="c-article-references__text" id="ref-CR73">Ushey, K. <i>et al</i>. reticulate: Interface to python. <i>R package version</i> <b>1</b>, 16 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 73" href="http://scholar.google.com/scholar_lookup?&amp;title=reticulate%3A%20Interface%20to%20python&amp;journal=R%20package%20version&amp;volume=1&amp;publication_year=2020&amp;author=Ushey%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="74."><p class="c-article-references__text" id="ref-CR74">Wickham, H., Francios, R., Henry, L. &amp; Muller, K. Dplyr: A fast, consistent tool for working with data frame like objects, both in memory and out of memory. <i>R package version 0.7</i> <b>6</b> (2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="75."><p class="c-article-references__text" id="ref-CR75">Tennekes, M. tmap: Thematic maps in r. <i>Journal of Statistical Software</i> <b>84</b>, 1–39 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.18637/jss.v084.i06" data-track-action="article reference" href="https://doi.org/10.18637%2Fjss.v084.i06" aria-label="Article reference 75" data-doi="10.18637/jss.v084.i06">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 75" href="http://scholar.google.com/scholar_lookup?&amp;title=tmap%3A%20Thematic%20maps%20in%20r&amp;journal=Journal%20of%20Statistical%20Software&amp;doi=10.18637%2Fjss.v084.i06&amp;volume=84&amp;pages=1-39&amp;publication_year=2018&amp;author=Tennekes%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="76."><p class="c-article-references__text" id="ref-CR76">Ooms, J. magick: Advanced graphics and image-processing in r. <i>R package version</i> <b>2</b> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="77."><p class="c-article-references__text" id="ref-CR77">Wilke, C. O. ggridges: ridgeline plots in ‘ggplot2’. <i>R package version 0.5</i> <b>1</b> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="78."><p class="c-article-references__text" id="ref-CR78">Wickham, H. ggplot2. <i>Wiley interdisciplinary reviews: computational statistics</i> <b>3</b>, 180–185 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/wics.147" data-track-action="article reference" href="https://doi.org/10.1002%2Fwics.147" aria-label="Article reference 78" data-doi="10.1002/wics.147">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 78" href="http://scholar.google.com/scholar_lookup?&amp;title=ggplot2&amp;journal=Wiley%20interdisciplinary%20reviews%3A%20computational%20statistics&amp;doi=10.1002%2Fwics.147&amp;volume=3&amp;pages=180-185&amp;publication_year=2011&amp;author=Wickham%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="79."><p class="c-article-references__text" id="ref-CR79">Hughes, M. J. &amp; Hayes, D. J. Automated detection of cloud and cloud shadow in single-date Landsat imagery using neural networks and spatial post-processing. <i>Remote Sensing</i> <b>6</b>, 4907–4926, <a href="https://doi.org/10.3390/rs6064907" data-track="click" data-track-action="external reference" data-track-label="10.3390/rs6064907">https://doi.org/10.3390/rs6064907</a> (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/rs6064907" data-track-action="article reference" href="https://doi.org/10.3390%2Frs6064907" aria-label="Article reference 79" data-doi="10.3390/rs6064907">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2014RemS....6.4907H" aria-label="ADS reference 79">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 79" href="http://scholar.google.com/scholar_lookup?&amp;title=Automated%20detection%20of%20cloud%20and%20cloud%20shadow%20in%20single-date%20Landsat%20imagery%20using%20neural%20networks%20and%20spatial%20post-processing&amp;journal=Remote%20Sensing&amp;doi=10.3390%2Frs6064907&amp;volume=6&amp;pages=4907-4926&amp;publication_year=2014&amp;author=Hughes%2CMJ&amp;author=Hayes%2CDJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="80."><p class="c-article-references__text" id="ref-CR80">Wu, Z., Li, J., Wang, Y., Hu, Z. &amp; Molinier, M. Self-attentive generative adversarial network for cloud detection in high resolution remote sensing images. <i>IEEE Geoscience and Remote Sensing Letters</i> <b>17</b>, 1792–1796 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/LGRS.2019.2955071" data-track-action="article reference" href="https://doi.org/10.1109%2FLGRS.2019.2955071" aria-label="Article reference 80" data-doi="10.1109/LGRS.2019.2955071">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020IGRSL..17.1792W" aria-label="ADS reference 80">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 80" href="http://scholar.google.com/scholar_lookup?&amp;title=Self-attentive%20generative%20adversarial%20network%20for%20cloud%20detection%20in%20high%20resolution%20remote%20sensing%20images&amp;journal=IEEE%20Geoscience%20and%20Remote%20Sensing%20Letters&amp;doi=10.1109%2FLGRS.2019.2955071&amp;volume=17&amp;pages=1792-1796&amp;publication_year=2019&amp;author=Wu%2CZ&amp;author=Li%2CJ&amp;author=Wang%2CY&amp;author=Hu%2CZ&amp;author=Molinier%2CM">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41597-022-01878-2?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>Sentinel-1, Sentinel-2 Level 1C and Level 2A data courtesy of ESA. This research was conducted during the master thesis of the first author, supported by the European scholarship to engage in the Master Copernicus in Digital Earth, an Erasmus Mundus Joint Master Degree (EMJMD, project reference: 599182-EPP-1-2018-1-AT-EPPKA1-JMD-MOB). The computational cost was partially covered by the Google Cloud Credits Research Grant Program with the award GCP19980904. This work was also partially supported by the Spanish Ministry of Science and Innovation (project PID2019-109026RB-I00, ERDF) and the Austrian Space Applications Programme within the SemantiX project (#878939, ASAP 16). The following R and Python packages were used in the course of this investigation and the authors wish to acknowledge their developers: “rgee”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="Aybar, C., Wu, Q., Bautista, L., Yali, R. &amp; Barja, A. rgee: An R package for interacting with Google Earth Engine. Journal of Open Source Software 5, 2272, &#xA;                  https://doi.org/10.21105/joss.02272&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR67" id="ref-link-section-d75612378e5810">67</a></sup>, “sf”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Pebesma, E. Simple features for R: Standardized support for spatial vector data. R Journal 10, 439–446, &#xA;                  https://doi.org/10.32614/rj-2018-009&#xA;                  &#xA;                 (2018)." href="/articles/s41597-022-01878-2#ref-CR68" id="ref-link-section-d75612378e5814">68</a></sup>, “raster”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 69" title="Hijmans, R. J. et al. Package ‘raster’. R package 734 (2015)." href="/articles/s41597-022-01878-2#ref-CR69" id="ref-link-section-d75612378e5818">69</a></sup>, “stars”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 70" title="Pebesma, E. stars: Spatiotemporal arrays, raster and vector data cubes. R package version 0.4–1 ed2020 &#xA;                  https://CRAN.R-project.org/package=stars&#xA;                  &#xA;                 (2020)." href="/articles/s41597-022-01878-2#ref-CR70" id="ref-link-section-d75612378e5822">70</a></sup>, “numpy”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 71" title="Harris, C. R. et al. Array programming with numpy. Nature 585, 357–362 (2020)." href="/articles/s41597-022-01878-2#ref-CR71" id="ref-link-section-d75612378e5826">71</a></sup>, “lubridate”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Grolemund, G. &amp; Wickham, H. Dates and times made easy with lubridate. Journal of statistical software 40, 1–25 (2011)." href="/articles/s41597-022-01878-2#ref-CR72" id="ref-link-section-d75612378e5831">72</a></sup>, “reticulate”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 73" title="Ushey, K. et al. reticulate: Interface to python. R package version 1, 16 (2020)." href="/articles/s41597-022-01878-2#ref-CR73" id="ref-link-section-d75612378e5835">73</a></sup>, “dplyr”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Wickham, H., Francios, R., Henry, L. &amp; Muller, K. Dplyr: A fast, consistent tool for working with data frame like objects, both in memory and out of memory. R package version 0.7 6 (2014)." href="/articles/s41597-022-01878-2#ref-CR74" id="ref-link-section-d75612378e5839">74</a></sup>, “tmap”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 75" title="Tennekes, M. tmap: Thematic maps in r. Journal of Statistical Software 84, 1–39 (2018)." href="/articles/s41597-022-01878-2#ref-CR75" id="ref-link-section-d75612378e5843">75</a></sup>, “magick”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 76" title="Ooms, J. magick: Advanced graphics and image-processing in r. R package version 2 (2020)." href="/articles/s41597-022-01878-2#ref-CR76" id="ref-link-section-d75612378e5847">76</a></sup>, ggridges<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 77" title="Wilke, C. O. ggridges: ridgeline plots in ‘ggplot2’. R package version 0.5 1 (2018)." href="/articles/s41597-022-01878-2#ref-CR77" id="ref-link-section-d75612378e5851">77</a></sup>, and “ggplot2”<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Wickham, H. ggplot2. Wiley interdisciplinary reviews: computational statistics 3, 180–185 (2011)." href="/articles/s41597-022-01878-2#ref-CR78" id="ref-link-section-d75612378e5856">78</a></sup>. The authors also thank to B.S. Joselyn Inga for their work reporting manual labeling errors in the quality control phase. Finally, the authors would like to thank Justin Braaten for developing “ee-rgb-timeseries” Earth Engine JavasScript module that served as the basis for creating Cloudapp.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Image Processing Laboratory, University of Valencia, 46980, Valencia, Spain</p><p class="c-article-author-affiliation__authors-list">Cesar Aybar, Gonzalo Mateo-García &amp; Luis Gómez-Chova</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Geoinformatics – Z_GIS, University of Salzburg, 5020, Salzburg, Austria</p><p class="c-article-author-affiliation__authors-list">Cesar Aybar, Martin Sudmanns &amp; Dirk Tiede</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">High Mountain Ecosystem Research Group, National University of San Marcos, 15081, Lima, Peru</p><p class="c-article-author-affiliation__authors-list">Cesar Aybar, Luis Ysuhuaylas, Jhomira Loja, Karen Gonzales, Fernando Herrera, Lesly Bautista, Angie Flores, Lissette Diaz, Nicole Cuenca, Wendy Espinoza &amp; Valeria Llactayo</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Research Group on Artificial Intelligence, Pontifical Catholic University of Peru, 15088, Lima, Peru</p><p class="c-article-author-affiliation__authors-list">Roy Yali</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">Sub-directorate of Atmospheric and Hydrospheric Sciences, Geophysical Institute of Peru, 15012, Lima, Peru</p><p class="c-article-author-affiliation__authors-list">Fernando Prudencio</p></li><li id="Aff6"><p class="c-article-author-affiliation__address">Remote Sensing Centre for Earth Systems Research (RSC4Earth), Leipzig University, 04103, Leipzig, Germany</p><p class="c-article-author-affiliation__authors-list">David Montero</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Cesar-Aybar-Aff1-Aff2-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Cesar Aybar</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Cesar%20Aybar" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Cesar%20Aybar" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Cesar%20Aybar%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Luis-Ysuhuaylas-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Luis Ysuhuaylas</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Luis%20Ysuhuaylas" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Luis%20Ysuhuaylas" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Luis%20Ysuhuaylas%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Jhomira-Loja-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Jhomira Loja</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Jhomira%20Loja" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jhomira%20Loja" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jhomira%20Loja%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Karen-Gonzales-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Karen Gonzales</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Karen%20Gonzales" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Karen%20Gonzales" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Karen%20Gonzales%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Fernando-Herrera-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Fernando Herrera</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Fernando%20Herrera" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Fernando%20Herrera" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Fernando%20Herrera%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Lesly-Bautista-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Lesly Bautista</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Lesly%20Bautista" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Lesly%20Bautista" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lesly%20Bautista%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Roy-Yali-Aff4"><span class="c-article-authors-search__title u-h3 js-search-name">Roy Yali</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Roy%20Yali" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Roy%20Yali" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Roy%20Yali%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Angie-Flores-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Angie Flores</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Angie%20Flores" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Angie%20Flores" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Angie%20Flores%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Lissette-Diaz-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Lissette Diaz</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Lissette%20Diaz" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Lissette%20Diaz" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lissette%20Diaz%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Nicole-Cuenca-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Nicole Cuenca</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Nicole%20Cuenca" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Nicole%20Cuenca" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Nicole%20Cuenca%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Wendy-Espinoza-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Wendy Espinoza</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Wendy%20Espinoza" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Wendy%20Espinoza" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Wendy%20Espinoza%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Fernando-Prudencio-Aff5"><span class="c-article-authors-search__title u-h3 js-search-name">Fernando Prudencio</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Fernando%20Prudencio" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Fernando%20Prudencio" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Fernando%20Prudencio%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Valeria-Llactayo-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Valeria Llactayo</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Valeria%20Llactayo" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Valeria%20Llactayo" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Valeria%20Llactayo%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-David-Montero-Aff6"><span class="c-article-authors-search__title u-h3 js-search-name">David Montero</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=David%20Montero" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=David%20Montero" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22David%20Montero%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Martin-Sudmanns-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Martin Sudmanns</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Martin%20Sudmanns" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Martin%20Sudmanns" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Martin%20Sudmanns%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Dirk-Tiede-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Dirk Tiede</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Dirk%20Tiede" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Dirk%20Tiede" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Dirk%20Tiede%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Gonzalo-Mateo_Garc_a-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Gonzalo Mateo-García</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Gonzalo%20Mateo-Garc%C3%ADa" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Gonzalo%20Mateo-Garc%C3%ADa" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Gonzalo%20Mateo-Garc%C3%ADa%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Luis-G_mez_Chova-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Luis Gómez-Chova</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Luis%20G%C3%B3mez-Chova" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Luis%20G%C3%B3mez-Chova" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Luis%20G%C3%B3mez-Chova%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>C.A. led the publication, wrote the article, co-developed the CloudSEN12 methodology, designed the worldwide data processing system, participated in the quality control phase, and co-created the website and figures. R.Y., F.H., J.L., K.G. and L.Y. led the quality control and calibration phase, co-created the figures, and performed the manual labeling generation. D.M. reported manual labeling errors, contributed to the methodology, co-created CloudSEN12 Python package, and participated in the technical validation. L.B. created the GEE cloudApp, performed the manual labeling generation, co-created the CloudSEN12 website, and participated in the quality control phase. G.M.G., L.G.C., D.T. and M.S. supervised the CloudSEN12 project, contributed to the methodology, and provided specialized advice. Besides, they reviewed the manuscript and participated in the quality control phase. L.D., A.F., W.E. and N.C. performed the manual labeling generation, participated in the quality control phase, and performed the statistical analysis. F.P. co-created the figures and participated in the quality control phase.V.LL report manual labeling errors and generate the metadata.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:csaybar@gmail.com">Cesar Aybar</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading" id="FPar1">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec20-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec20">Supplementary information</h2><div class="c-article-section__content" id="Sec20-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figures" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41597-022-01878-2/MediaObjects/41597_2022_1878_MOESM1_ESM.pdf" data-supp-info-image="">Supplementary Figures</a></h3></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=CloudSEN12%2C%20a%20global%20dataset%20for%20semantic%20understanding%20of%20cloud%20and%20cloud%20shadow%20in%20Sentinel-2&amp;author=Cesar%20Aybar%20et%20al&amp;contentID=10.1038%2Fs41597-022-01878-2&amp;copyright=The%20Author%28s%29&amp;publication=2052-4463&amp;publicationDate=2022-12-24&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/s41597-022-01878-2" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41597-022-01878-2" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Aybar, C., Ysuhuaylas, L., Loja, J. <i>et al.</i> CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2.
                    <i>Sci Data</i> <b>9</b>, 782 (2022). https://doi.org/10.1038/s41597-022-01878-2</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41597-022-01878-2?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-09-05">05 September 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-11-29">29 November 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-12-24">24 December 2022</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/s41597-022-01878-2</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Global flood extent segmentation in optical satellite images" href="https://doi.org/10.1038/s41598-023-47595-7">
                                        Global flood extent segmentation in optical satellite images
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Enrique Portalés-Julià</li><li>Gonzalo Mateo-García</li><li>Luis Gómez-Chova</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2023)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            
                
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41597-022-01878-2.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

            
        
    </div>

    
        
    

    
    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/sdata.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=s41597-022-01878-2;doi=10.1038/s41597-022-01878-2;subjmeta=106,210,35,445,704,823;kwrd=Atmospheric+dynamics,Geodynamics">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/sdata.nature.com/article&amp;sz=300x250&amp;c=-1647114041&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41597-022-01878-2%26doi%3D10.1038/s41597-022-01878-2%26subjmeta%3D106,210,35,445,704,823%26kwrd%3DAtmospheric+dynamics,Geodynamics">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/sdata.nature.com/article&amp;sz=300x250&amp;c=-1647114041&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41597-022-01878-2%26doi%3D10.1038/s41597-022-01878-2%26subjmeta%3D106,210,35,445,704,823%26kwrd%3DAtmospheric+dynamics,Geodynamics"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://www.facebook.com/scientificdata"
                               data-track="click"
                               data-track-action="facebook"
                               data-track-label="link">Follow us on Facebook
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/scientificdata"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;329"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/sdata.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/principles"
                                   data-track="click"
                                   data-track-action="principles"
                                   data-track-label="link">
                                    Principles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/oa"
                                   data-track="click"
                                   data-track-action="open access"
                                   data-track-label="link">
                                    Open Access
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/publish"
                                   data-track="click"
                                   data-track-action="publish"
                                   data-track-label="link">
                                    Publish
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/faq"
                                   data-track="click"
                                   data-track-action="faq"
                                   data-track-label="link">
                                    FAQ
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/calls-for-papers"
                                   data-track="click"
                                   data-track-action="calls for papers"
                                   data-track-label="link">
                                    Calls for Papers
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/editorial-board"
                                   data-track="click"
                                   data-track-action="editors &amp; editorial board"
                                   data-track-label="link">
                                    Editors &amp; Editorial Board
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/policies"
                                   data-track="click"
                                   data-track-action="policies"
                                   data-track-label="link">
                                    Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/sdata/author-instructions"
                                   data-track="click"
                                   data-track-action="for authors"
                                   data-track-label="link">
                                    For Authors
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="http://www.nature.com/sdata/publish"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="sdata">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Scientific Data (<i>Sci Data</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">2052-4463</span> (online)
    </span>
    


                
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.protocols.io/"
                                                  data-track="click" data-track-action="protocols.io"
                                                  data-track-label="link">protocols.io</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/s41597-022-01878-2&amp;format=js&amp;last_modified=2022-12-24" async></script>
<img src="/n4t7191c/article/s41597-022-01878-2" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>